We thank the reviewers for their comments which we found useful.

Reviewer 1:
-----------
1. Indeed, there are some regrettable errors in Table 1, which we will correct as suggested.
2. Theorem 1 (upper bound) does support q=0 with no change (in fact, the fully general result, Lemma 1, in the appendix, also allows p=0). The proof of Theorem 2 (lower bound) works with no change with q>0; and then extends to q=0 by continuity. The condition q>=2 stated in Theorem 2 is an unfortunate remainder of a previous iteration of the proof, but it is unnecessary. Using p=0 with C_1>0 means a constant, unreducable bias, which by tweaking the lower bound proof will lead to an Omega(1) lower bound (as it should). p=0, C_1=0 can also be handled. We will clarify these in the revision.
3. We will include the suggested reference with discussion.

Reviewer 2:
-----------
(1) .. bad dependence on $n$ .. well known: Indeed, the poor behavior has been suspected since long. Our main contribution is making steps towards solidifying this "folk-theorem" in the form of rigorous lower bounds (as noted in the third paragraph of the introduction. We will be happy to clarify that our results confirm a long-held belief as opposed to establishing results with no precedence.
(2) .. conclusions a bit weaker ..: We tried to be precise in our claims, in particular, to avoid the suspected overstatement. Indeed, we only wanted to claim that if a proof for a gradient method uses only the stated bias-variance tradeoff, then the stated lower bound applies.
We will double-check the paper and correct all existing overstatements if any in the revision. We will also make sure that we properly highlight the limitations of the approach. Re better gradient-estimators: Interesting problem; we are currently working on this. Re worst-case oracles: True, though any reasonable noise is fine (e.g., we have a proof, not shown, with scaled and shifted Bernoulli noise).


We agree that a lot of work has been done to deal with the bias-variance tradeoff of gradient estimates, but--at the moment--they all lead to suboptimal error rates. This was the main motivation of our work: to clarify the fundamental limits achievable this way. Our definition of the gradient oracles aims at abstracting out the properties generally used about gradient estimators in the literature (and captures the properties of the numerous gradient estimation techniques used in the literature). Indeed, our upper bound is not particularly novel, by generalizing existing results to the framework we consider. Our main results are the lower bounds (and their relations to the upper bounds), which imply that the current gradient estimators and/or the proof techniques used to analyze the algorithms based on them cannot lead to optimal performance. This indicates that either some other properties of the gradient estimators have to be utilized or new gradient estimates are needed that exhibit a better bias-variance tradeoff, or completely different methods are necessary to achieve optimal rates. Concerning our specific construction in the lower bounds, we would like to point out that one can construct several other noise models than the proposed Gaussian one, for example, it is not hard to modify the argument to have bounded noise (scaled and shifted Bernoulli). However, irrespective of the actual noise of an estimator, the minimax nature of the lower bound shows that if a proof utilizes only the usual bias-variance bounds on the oracle, it cannot yield an optimal rate. Of course, our results would be significantly stronger if we could show that no better estimators are possible, that is, if the variance is bounded by delta^{-q}, the bias has to be at least delta^p, but so far we have not been able to show this (and it is known to be false for some special problems, see the response to Reviewer 3 below). Nevertheless, our results still correspond to the gradient estimates and upper bound proof techniques available in the literature (see also our analysis of the bias-variance tradeoff of different estimators in Appendix C).


Reviewer 3:
-----------
Although we missed the paper of Honorio [H12], we never intended to claim that we are the first to study gradient methods with biased and noisy gradient estimates (see Section 5 for the references we found). We will be happy to include a reference to this paper with a short discussion. In particular, as far as we saw, [H12] differs in multiple ways from our paper: He studies a special optimization problem (not general bandit convex optimization) and considers only upper bounds. Also, his setting does not allow changing delta (our setting naturally allows the algorithms to take more samples at a given point, and by using a specific choice for delta can reproduce his setting with q=0).
