%!TEX root =  bgo_camera_ready.tex
% please do not delete or change the first line (needed by Csaba's editor)
The main application of the biased noisy gradient oracle based convex optimization of the previous section
is to bandit convex optimization, which we briefly introduce now. Readers familiar with these problems and the associated
gradient estimation techniques, may skip this description to jump directly to \cref{thm:aaa},
and come back to it only to clarify our notation and terminology in case some confusion arises later.

\if0
For example, \cite{AgDeXi10} used an algorithm that queries at two points per round, and defined the incurred loss as the average of losses at the two observation points. In our oracle, it can be stated as in round $t$, the same oracle $\gamma_t$ responds to the same inputs $(X_t, \delta_t, f_t)$ with two different pairs $(G_{t,1}, Y_{t,1})$ and $(G_{t,2}, Y_{t,2})$. The accumulated regret can be written as
$% \[
R_n = \sum_{t=1}^n \dfrac{1}{2}\left( f_t(Y_{t,1})+f_t(Y_{t,2}) \right) -\inf_{x \in \cK}\sum_{t=1}^n f_t(x) \,.
$ %\]
Recalling that $Y_{t,1}$, $Y_{t,2}$ are in the $\delta$-vicinity of $X_t$, the relationship between $f_t(X_t)$ and $\dfrac{1}{2}\left( f_t(Y_{t,1})+f_t(Y_{t,2})\right)$ is then determined by the environment (i.e. the property of $f_t$). It is straightforward to bound $| \dfrac{1}{2}\left( f_t(Y_{t,1})+f_t(Y_{t,2})\right)- f_t(X_t)|$ as a function of $\delta$. \todoc{How? When $f_t$ is Lipschitz, smooth, etc? So you mean, when $f_t$ is a smooth function?}
The common assumption for this setting is: The oracle is a stochastic mapping from $(X, \delta, f)$ to $(G, Y)$; The algorithm selects the point $X_t$ depending on $\left( X_1, G_{1,1}, G_{1,2}, \cdots, X_{t-1},G_{t-1,1}, G_{t-1,2}  \right)$. This two-point feedback can be easily extended to multi-point feedback, too.
\fi

In the \emph{stochastic BCO} setting,
the algorithm sequentially chooses the points $X_1,\dots,X_n\in \cK$ while observing the loss function at these points in noise.
In particular, in round $t$, the algorithm chooses $X_t$ based on the earlier observations $Z_1,\dots,Z_{t-1}\in \R$ and $X_1,\dots,X_{t-1}$, after which it observes $Z_t$, where $Z_t$ is the value of $f(X_t)$ corrupted by ``noise''.
Previous research considered several possible constraints connecting $Z_t$ and $f(X_t)$.
One simple assumption is that $Z_t-f(X_t)$ is an $\cF_t = \sigma(X_{1:t},Z_{1:t-1})$-adapted martingale difference sequence (with favourable tail properties).
% \todoc{Some readers might be put off by martingales..}
A specific case is when $Z_t - f(X_t) = \xi_t$, where $(\xi_t)$ is an i.i.d. sequence.
A stronger assumption, which is most appropriate in stochastic programming,
is that $Z_t = F(X_t,U_t)$, where $U_t\in \R$, $\int F(X_t,u) dP_U(u) = f(X_t)$ with some distribution function $P_U$ over the reals and the algorithm has access to an oracle that can produce independent samples from $F$ (in which case, $(U_t)$ may be an i.i.d. sequence sampled from $P_U$).
This assumption is stronger because the algorithm controls the
``noise''.
For instance, the algorithm may obtain samples of $F$ at $X^+$ and $X^-$, with the same noise levels, i.e., $\xi^+=\xi^-$.
Controlling the noise this way helps in improving the accuracy of the estimates and is common in the field of \textit{simulation optimization},.
Again, it is also possible to consider multi-point feedback as in the online case.

However, what differs in the optimization variant is that the value of the loss at the points sent to the oracle does not matter.
Hence, in this setting the distinction between one-point and multi-point feedback (as long as the number observations is fixed, independently of the dimension) is irrelevant:
By grouping $K$ multiple consecutive observations, one can turn an $n$ rounds one-point feedback setup into an $n/K$-round $K$-point feedback setup. The reduction in the number of rounds, being a fixed constant factor, is negligible, as far as the convergence rates are considered.


%A major tool in bandit convex optimization is to design gradient estimators, which are then used in conjunction with variants of gradient descent. \todoc{zillions of references.}
A common popular idea in bandit convex optimization is to use the bandit feedback to construct noisy (and biased) estimates of the gradient.
In the following, we provide a few examples for oracles that construct gradient estimates for function classes that are increasingly general - from smooth, convex to non-differentiable functions.

\paragraph{One-point feedback}
Given $x\in \cK$, $0<\delta\le 1$, common gradient estimates that are
based on a single query to the function evaluation oracle (the so-called
``one-point feedback'') take the form
\begin{align}
  \label{eq:one-point}
G = \frac{Z}{\delta}V, \textrm{ where } Z = f(x+\delta U) + \xi\,,
\end{align}
where $(U,V)\in \R^d\times \R^d$ are jointly distributed random variables
and $\xi$ is the function evaluation noise (the distribution of $\xi$ may depend on $x+\delta U$) and $G$ is the estimate of $\nabla f(x)$ ($f:\cK\to \R$).

In all oracle constructions we will use the following assumption:
\begin{ass}
  \label{ass:gradbasic}
  $\K \subset \D^\circ \subset \R^d$, where $f:\D \to \R$.
  \footnote{Here, $\D^\circ$ denotes the interior of $\D$.}
  The joint distribution for $(U,V)$ is such that
  for any $x\in \K$, $x+\delta U \in \D$ a.s.,
  $\E[V U\tr] = I$, while
  $\EE{\norm{V}_*^2}$, $\EE{ \norm{U}^3 }<+\infty$.
\end{ass}

For uncontrolled noise, this can be shown to be a $(c_1,c_2)$ Type-I oracle with slightly stronger assumptions on $(U,V)$ (e.g., $U$ symmetrically distributed, $V = h(U)$, with $h$ odd in addition to the previous assumptions)
with $(c_1,c_2)$ essentially the same as before, except that now instead of the span of $f$, the magnitude of $f$ appears in the bound. For the controlled noise case, the oracle has the same variance as in the case of uncontrolled noise, because this oracle does not ``cancel out'' the noise.%
This is exactly the property that is exploited by \cite{duchi2015optimal}.

\begin{proposition}
\label{prop:grad-onepoint}
Let $f:\cD \to \R$ and let $\gamma$ be the one-point feedback oracle defined in \eqref{eq:one-point}.
Let \cref{ass:gradbasic} hold.
Assume further that
  $U$ is symmetrically distributed,
  $V = h(U)$, where $h:\R^d \to \R^d$ is an odd function,
  and
  $\EE{V}=0$,
Then, $\gamma$ is a type-I oracle with $c_1(\delta)$ and $c_2(\delta)$ same as the uncontrolled noise case in \cref{tab:oracles}.
% \todoc{Add the convex+smooth case}
\end{proposition}
\begin{proof}
See Section \ref{sec:appendix-grad}.
\end{proof}

\paragraph{One-point feedback with smoothing}
Another possibility is to use the so-called smoothing technique
\citep{PoTsy90,flaxman2005online,HaLe14:SOC}\todoa{ Cs: Is this correct?}
to obtain type-II oracles, see \cref{prop:flaxman}.
While the one-point estimators are intriguing, as discussed beforehand,
in the optimization setting one can also always group two consecutive observations and obtain similar smoothing-type estimates (see, e.g., the above discussion on the choice of $U$ and $V$)
%\citep[see][]{katkul,kushcla,spall1992multivariate,spall1997one,bhatnagar-book,duchi2015optimal}
at the price of reducing the number of rounds by a factor of two only, which has a negligible effect on the rate of convergence.

Type-II oracles can be obtained using the same construction as above, but with a different analysis:
\begin{proposition}
\label{prop:flaxman}
For the one-point feedback oracle stated in \cref{prop:grad-onepoint}, let
\begin{align*}
V = n_W(U)\dfrac{\lvert \partial W\rvert}{\lvert W \rvert}\,,
\end{align*}
where $W \subset \R^n$ is a convex body with the boundary $\partial W$, $U \in \partial W$ is uniformly distributed. $n_W(U)$ denotes the normal vector of $\partial W$ at $U$, and $\lvert \cdot \rvert$ denotes the volume.
Then, if $f$ is Lipschitz, $\gamma$ is a type-II oracle with $c_1(\delta)=C_1 \delta$, $c_2(\delta) = C_2/\delta^2$.
If $f$ is smooth, further assuming $W$ is symmetric w.r.t. the origin, $\gamma$ is a type-II, and also a type-IIb oracle with $c_1(\delta) = C_1\delta^2$, $c_2(\delta) = C_2/\delta^2$. Hence, in this case $\gamma$ is also a type-I oracle with the same $c_1$ and $c_2$.
\end{proposition}
\begin{proof}
See Section \ref{sec:appendix-grad}.
\end{proof}



\paragraph{Two-point feedback}
Here we present an oracle that uses two function evaluations to obtain a gradient estimate.
As will be discussed later, this oracle
 encompasses several simultaneous perturbation methods (see \cite{bhatnagar-book}):
Given the inputs $x\in \K$,  $0<\delta\le 1$,
% \todoc{We need an upper bound I believe. Add it earlier.}
the gradient estimate is
\begin{align}
G &=  \dfrac{Z^+ - Z^-}{2\delta}\, V \,, 
 \label{eq:twosp}
\end{align}
where $Z^{\pm} = f(X^{\pm}) + \xi^{\pm}$, $X^{\pm} = x \pm \delta U$, $U,V\in \R^d$, $\xi^{\pm}\in \R$ are random, jointly distributed random variables, $U,V$ chosen by the oracle
from some fixed distribution characterizing the oracle and $\xi^{\pm}$ being the noise of the returned feedback $Z^{\pm}$ at points $X^{\pm}$.
For the following proposition we consider $4=2\times 2$ cases.
First, the function is either assumed to be $L$-smooth and convex (i.e., the derivative of $f$ is $L$-Lipschitz w.r.t. $\norm{\cdot}_*$), or it is assumed to be three times continuously differentiable (in notation: $f\in C^3$).
The other two options are that either $\xi^+=\xi^-$, which we call the \emph{controlled noise} setting, or we make the alternate assumptions
\begin{align}
\E[\xi^+-\xi^- |\, U,V] = 0 \text{~~ and ~~}\nonumber\\
\E [ (\xi^{+} - \xi^-)^{2} \mid V] \le \sigma_\xi^2 <\infty\,.
\label{eq:noiseass}
\end{align}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{table*}
\small
\centering
\begin{tabular}{|c|c|c|}
\toprule
\textbf{Noise }$\bm{ \rightarrow}$ & \multirow{2}{*}{\textbf{Controlled }($\bm{\xi^+ = \xi^-}$)} & \multirow{2}{*}{\textbf{Uncontrolled }(see~\eqref{eq:noiseass})} \\
\textbf{Function } &&\\
$\bm{\downarrow}$ &&\\\midrule
\multirow{2}{*}{\textbf{Convex + Smooth}} & \multirow{2}{*}{$(C_1 \delta, C_2)$} & \multirow{2}{*}{$(C_1\delta, C_2/\delta^2)$}\\
 &&\\\midrule
\multirow{2}{*}{$\bm{f \in \C^3}$} & \multirow{2}{*}{$(C_1 \delta^2, C_2/\delta^2)$} & \multirow{2}{*}{$(C_1 \delta^2, C_2/\delta^2)$} \\
 &&\\\bottomrule
\end{tabular}
\caption{Gradient oracles for different function classes and noise categories. Each table entry specifies the pair $(c_1(\delta), c_2(\delta))$.
For the first row, $C_1 =
\frac{L}{2} \E[ \dnorm{V} \norm{U}^2]$ and
$C_2 =   L^2 (2 + \frac{1}{2}\E\left[ \dnorm{V}^2 \norm{U}^4 \right])$
for the controlled noise and
 $C_2 =  C_{2}^{(u)} \doteq 4 \EE{\norm{V}_*^2}\left( \sigma_\xi^2+\fspan(f)\right)$ for the uncontrolled noise.
For the second row, $C_1 = \frac{B_3 \EE{ \norm{V}_* \norm{U}^3 }}{6}$ and $C_2 =  C_{2}^{(u)}$,
with $B_3 = \sup_{x\in \K} \norm{\nabla^3 f(x)}$, where $\norm{\cdot}$ is the implied norm for rank-3 tensors.
}
\label{tab:oracles}
\end{table*}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
The following proposition provides conditions under which the bias-variance parameters $(c_1,c_2)$ can be bounded as shown in \cref{tab:oracles}:
\begin{proposition}
\label{prop:grad-spsa}
Consider a function $f:\D \to \R$, with $\K \subset \D^\circ \subset \R^d$.%
\footnote{Here, $\D^\circ$ denotes the interior of $\D$.}
For any $x \in \cK$, and $0< \delta \le 1$ let the oracle $\gamma$ return $G$ as specified in~\eqref{eq:twosp},
where $(U,V)$ are such that $x+\delta U \in \D$ a.s.,
$\E[V U\tr] = I$, while
$\EE{\norm{V}_*^2}$ and $\EE{ \norm{U}^3 }<+\infty$.
Then, we have that $\gamma$ is a type-I oracle with $c_1(\delta)$ and $c_2(\delta)$ given by \cref{tab:oracles}.
\end{proposition}
\begin{proof}
See Section \ref{sec:appendix-grad}.
\end{proof}
\todoc[inline]{I am pretty sure that the bias could be brought down
for two-point feedback, too, using the technique of \cref{prop:flaxman}.
}

\paragraph{Popular choices for $V$ and $U$:}
\begin{inparaenum}[$\bullet$]
 \item If we set $U_i$ to be independent, symmetric $\pm 1$-valued r.v.s and $V_i = 1/U_i$, then we recover the popular SPSA scheme proposed by \cite{spall1992multivariate}.
It is easy to see that $\EE{  V U\tr } = I$ holds in this case.
 When the norm $\norm{\cdot}$ is the $2$-norm, $C_1 = O(d^2)$ and $C_2 = O(d)$. If we set $\norm{\cdot}$ to be the max-norm, $C_1 = O(\sqrt{d})$ and $C_2 = O(d)$.
 \item If we set $V=U$, with $U$ chosen uniform at random on the surface of a sphere with radius $\sqrt{d}$,
 then we recover the RDSA scheme proposed by  \citeauthor{kushcla} \citep[cf. pp.~58--60][]{kushcla}.
 In particular, $(U_i)_i$ are identically distributed with $\EE{ U_i U_j } = 0$ if $i\ne j$ and $\EE{ U\tr U } = d$, hence $\EE{U_i^2} = 1$. Thus, if we choose $\norm{\cdot}$ to be the $2$-norm, $C_1 = O( d^2 )$ and $C_2 = O(d)$.
 \item If we set $V=U$, with $U$ the standard $d$-dimensional Gaussian with unit covariance matrix, we recover the smoothed functional (SF) scheme proposed by \cite{katkul}.
Indeed, in this case, by definition, $\EE{VU\tr} = \EE{U U\tr } = I$.
When $\norm{\cdot}$ is the $2$-norm, $C_1 = O(d^2)$
%$\norm{U}^4 = (\sum_{i=1}^d U_i^2)^{2} = \sum_i U_i^4 + 2 \sum_{i<j} U_i^2 U_j^2$,
%hence $\EE{ \norm{U}^4} = O(d^2)$
 and $C_2 = O( d)$.
 This scheme can also be interpreted as a smoothing operation that  convolves the gradient of the function $f$ with a Gaussian density.
%  , followed by an integration by parts and the resulting integral can be estimated using samples (without access to the gradient of $f$).
\end{inparaenum}


% If the function $f$ is assumed to be convex and smooth, then gradient estimates similar to \eqref{eq:twosp} can be constructed and this does not require higher order smoothness conditions as in Proposition \ref{prop:grad-spsa}.
% \begin{proposition}
% \label{prop:grad-convex}
% Consider a function $f:\D \to \R$, with $\K \subset \D \subset \R^d$,
% that is convex and has a $L$-Lipschitz continuous gradient. .
% For any $x \in \cK$, and $\delta >0$ such that $\B(x,\delta) \in \D$, let the oracle $\gamma$ return
% \begin{align}
% % Y = x+\delta U \,, \quad
% G =  V \left(\dfrac{f(x+\delta U) + \xi^+ - (f(x-\delta U) + \xi^-)}{2\delta}\right),
%  \label{eq:twosp}
% \end{align}
% where $\xi^+, \xi^-$, $V$, $U$ are as in Proposition \ref{prop:grad-spsa}.
% Then, we have that $\gamma$ is a type-I oracle with $c_1(\delta) = C_1 \delta$ and $c_2(\delta) = C_2 d/\delta^2$.
% \end{proposition}
% \begin{proof}
% See Appendix \ref{sec:appendix-grad}.
% \end{proof}


% A popular idea for estimating gradient using one-point feedback is the smoothed function approach, which was originally proposed in \citep{katkul}. The idea is to convolve the gradient of the objective function with a suitable density function and then, via an integration by parts arguments show that the resulting integral is an estimate of the gradient of the smoothed objective function.
% This approach has been adopted in a stochastic convex optimization setup in \cite{duchi2015optimal}.

%% \paragraph{Simultaneous perturbation methods:}
%The idea of simultaneous perturbation can work even for functions that are not differentiable, as shown in \cite{flaxman2005online}.
%% follow this approach in the context of bandit convex optimization.
%Formally,
%% a $(c_1,c_2)$ Type-II oracle when $\cF$ is a general class of functions (this does not even require differentiability).
%given any $f \in \cF$, $x \in \cK$, and $\delta >0$, the oracle returns\footnote{See also \cite[pp.~58-60]{kushcla} for an old reference that proposed a gradient estimate similar to \eqref{eq:flaxman}.}
%\begin{align}
% Y = x+\delta u \in \cK', \quad
% G = \dfrac{d}{\delta}f(x+\delta u)u \in \R^d, \label{eq:flaxman}
%\end{align}
%where $u\in \R^d$ is a random unit vector, so the first condition of \cref{def:oracle2} immediately follows.
%The variance of $G$ is bounded by $d^2C^2 \delta^{-2}$ for some constant $C = \sup_{y\in \cK'}f(y)$.
%\todox[inline]{Fix this proposition statement to say Flaxman scheme is a type II oracle}
%\begin{proposition}
%Let $\tilde{f}(x) = \EE{f(x+\delta v)}$ denote the smoothed version of $f$. Then, we have
%$\EE{G} = \nabla \tilde{f}(x)$.
%\end{proposition}
%\begin{proof}
% See Lemma 1 in \citep{flaxman2005online}.
%\end{proof}
% As to the bias condition, it was proved that $\EE{G} = \nabla \tilde{f}(x)$, where $\tilde{f}$ is a smoothed version of $f$, i.e.,
%$\tilde{f}(x) = \EE{f(x+\delta v)}$,
%$v$ is a random vector in a unit ball. There are different ways to bound the bias depending on the property of $f$.
%If $f$ is $L_{lip}$-Lipschitz over $\cK'$, then we have
%\begin{align*}
%\MoveEqLeft
%\norm{\tilde{f}(x)-f(x)}_\infty \\
%=&\norm{\EE{f(x+\delta v)-f(x)}}_\infty
%\le L_{lip} \delta \,.
%\end{align*}
%If $f$ is convex, and $L_{smo}$-smooth,
%\begin{align*}
%\MoveEqLeft
%\norm{\tilde{f}(x)-f(x)}_\infty \\
%\le& \norm{\EE{\ip{\nabla f(x), \delta v}+\dfrac{L_{smo}}{2}\delta^2\norm{v}^2}}_\infty\\
%\le &\dfrac{L_{smo}}{2}\delta^2 \,.
%\end{align*}
%Therefore, the estimator \eqref{eq:flaxman} can always fit the oracle setting by choosing $c_1(\delta) = C_1 \delta$ (or $C_1\delta^2$), $c_2(\delta) = C_2 \delta^{-2}$, for some constant $C_1$, $C_2$.

% \begin{remark}
%  Instead of picking $u$ randomly on the surface of a unit sphere, one can employ an random variable $u$ that satisfies $E[u u\tr] = I_d$, where $I_d$ is the $d$-dimensional identity matrix. A popular choice for $u$ that satisfies the aforementioned constraint is the $d$-dimensional standard Gaussian - a choice that has been explored in the context of zeroth order optimization in \citep{duchi2015optimal}. See \citep{bhatnagar-book} for an overview of gradient and Hessian estimation techniques using random perturbations.
% \end{remark}

It may be noticed that the function domain $\D$ can be larger than or equal to the set $\K$, where the algorithm chooses $x$. This is to ensure that the oracle will not receive invalid inputs, i.e., queries where $f$ is not defined.
When the functions are defined over $\K$ only and $\K$ is bounded, the above constructions only work for $\delta$ small enough.
In this case, the best approach perhaps is to use Dikin ellipsoids to construct the oracles, as done by \citet{HaLe14:SOC}.

\paragraph{Results for stochastic BCO}
We know consider stochastic BCO with $L$-smooth functions over a convex, closed non-empty domain $\K$. \todoc{Check that $K$ is always assumed to be close. Otherwise the optimum may not belong to $K$.}
Let $\cF$ denote the set of these functions.
\cite{duchi2015optimal} proves that minimax expected optimization error
for the functions $\cF$ with uncontrolled noise is lower bounded by $\Omega(n^{-1/2})$. \todoc{We should sort out dimension dependences later.}
They also give an algorithm which uses two-point gradient estimates which matches this lower bound for the case of \emph{controlled noise}.
For controlled noise, the previous section's construction give that for two-point estimators $c_1(\delta) = C_1 \delta^p$ and $c_2(\delta) = C_2\delta^{-q}$ with $p=1$ and $q=0$. Plugging this into
\cref{thm:ub} we get the rate $O(n^{-1/2})$ (which is unsurprising
given that the algorithms and the upper bound proof techniques are essentially the same as that of \cite{duchi2015optimal}).
However, when the noise is uncontrolled, the best that we get is $p=1$ and $q=2$ (if, in addition, $f\in \C^3$, then we get $p=2$, $q=2$).
From \cref{thm:lb-convex} we get that with such oracles, no algorithm can get better rate than $\Omega(n^{-1/4})$ (resp., $\Omega(n^{-1/3})$), while from
\cref{thm:ub} we get that these rates are matched by mirror descent.
We can summarize these findings as follows:
\todoc{Can we show that no better oracles exist?}
\begin{theorem}\label{thm:aaab}
Let $\cF$ be the space of convex, $L$-smooth functions over a convex, closed non-empty domain $\K$.
Then, we have that\\
\textit{\textbf{Uncontrolled noise}}:
Take any $(\delta^1,\delta^{-2})$ type-I oracle $\gamma$.
There exists an algorithm that uses $\gamma$
and achieves the rate $O(n^{1/4})$.
Furthermore, no algorithm using $\gamma$
 can achieve better error than $\Omega(n^{-1/4})$.\\
\textit{\textbf{Uncontrolled noise}, $f\in \C^3$}:
Take any $(\delta^2,\delta^{-2})$ type-I oracle $\gamma$.
There exists an algorithm that uses $\gamma$
and achieves the rate $O(n^{1/3})$.
Furthermore, no algorithm using $\gamma$
 can achieve better error than $\Omega(n^{-1/3})$.\\
\textit{\textbf{Controlled noise}}:
Take any $(\delta,1)$ type-I oracle $\gamma$.
There exists an algorithm that uses $\gamma$ an
achieves the rate $O(n^{-1/2})$.
Furthermore, no algorithm using $\gamma$
 can achieve better error than $\Omega(n^{-1/2})$.
\end{theorem}

For stochastic BCO with uncontrolled noise, \cite{AgFoHsuKaRa13:SIAM} analyse a variant of the well-known ellipsoid method and provide regret bounds for the case of convex, $1$-Lipschitz and bounded functions on $[0,1]$. Their regret bound implies a minimax error \eqref{eq:minimaxerrdef} bound of the order  $O\left(\sqrt{d^{32}/n}\right)$.
%\todoc{Not for this setting! This paper should be mentioned in the previous section actually. For this setting, we  do not have \emph{any} algorithms that would achieve $O(n^{1/2})$.}
\cite{liang2014zeroth} provide an algorithm based on random walks (and not using gradient estimates) for the setting of convex, bounded functions whose domain is contained in the unit cube and their algorithm results in a bound of the order $\O\left((d^{14}/n)^{1/2}\right)$ for the minimax error.
%\todoc{What are the conditions for their theorem? Boundedness? Lipschitzness? Or nothing?}
%This algorithm achieves an upper bound of $\O\left((d^{14}/n)^{1/2}\right)$,
These bounds decrease faster in $n$ than the bound available in Theorem \ref{thm:aaab}, while showing a much worse dependence on the dimension.\todoc{We should show the dimension dependence in the result to make this point. This should be shown for the same setting as the one considered by \cite{liang2014zeroth}.}
However, what is more interesting is that our results also shows that an $O(n^{-1/2})$ upper bound \emph{cannot} be achieved using the gradient oracles available for this setting, no matter what algorithm would be used used to interact with these oracles.

The above result also shows that the gradient oracle based algorithms are optimal for smooth problems, under a controlled noise setting.
While \cite{duchi2015optimal} suggests that it is the power of two-point gradient estimators that help to achieve this, we need to add that a critical condition to achieve the optimal rate is that the noise must be controlled. For the case of uncontrolled noise, the best known upper bound for convex+smooth functions is $O(n^{-1/3}$ and this is due to \cite{saha2011improved}.

Finally, let us make some remarks on the early literature on this problem.
A finite time lower bound for stochastic, smooth BCO is presented by  \citet{Chen88:LB-AoS} for
convex functions on the real line.
While the lower bound is stated for $r$-smooth functions with $r$ odd (these are functions $f$ with $\norm{f^{(r)}}_{\infty}\le L$), and $r$ greater than one, careful checking of the results show that nor $r>1$, neither that $r$ must be odd is ever used in the proof.
Hence, the result holds for $r\ge 2$.
The lower bound presented for a given value of $r$ takes the form $\Omega( (1/n)^{ (r-1)/(2r)} )$. For $r=2$ (which approximately corresponds to the smooth case), we get $\Omega((1/n)^{1/4})$, while for $r=3$ (which is ``almost'' the same as $f\in \C^3$), one gets $\Omega((1/n)^{1/3})$.
While these match the bounds in \cref{thm:aaab}, they are larger than the error achieved by
the algorithm of \cite{liang2014zeroth}. The resolution of the apparent contradiction is that the lower bounds of \citet{Chen88:LB-AoS} concern distance to the optimum (i.e., $\EE{ \norm{\hat{X}_n - x^* }}$), while the optimization error is defined in terms of the objective function gap $\EE{ f(\hat{X}_n) -f( x^*)}$.
Similar results are obtained by \citet{PoTsy90}, who also consider distance to the optimum and proves that mirror descent with gradient estimation achieves asymptotic optimal rates for these settings.

\todoc{Cite all the other papers, summarizing what they achieve. }

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "bgo"
%%% End:
