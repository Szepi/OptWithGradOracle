%!TEX root =  bgo-cam-ready.tex
% please do not delete or change the first line (needed by Csaba's editor)
The main application of the biased noisy gradient oracle based convex optimization of the previous section
is bandit convex optimization. We introduce here briefly the stochastic version of the problem, while online BCO will be considered in Section~\ref{sec:obco}. Readers familiar with these problems and the associated
gradient estimation techniques, may skip this description to jump directly to \cref{thm:aaa},
and come back to it only to clarify our notation and terminology in case some confusion arises later.

\if0
For example, \cite{AgDeXi10} used an algorithm that queries at two points per round, and defined the incurred loss as the average of losses at the two observation points. In our oracle, it can be stated as in round $t$, the same oracle $\gamma_t$ responds to the same inputs $(X_t, \delta_t, f_t)$ with two different pairs $(G_{t,1}, Y_{t,1})$ and $(G_{t,2}, Y_{t,2})$. The accumulated regret can be written as
$% \[
R_n = \sum_{t=1}^n \dfrac{1}{2}\left( f_t(Y_{t,1})+f_t(Y_{t,2}) \right) -\inf_{x \in \cK}\sum_{t=1}^n f_t(x) \,.
$ %\]
Recalling that $Y_{t,1}$, $Y_{t,2}$ are in the $\delta$-vicinity of $X_t$, the relationship between $f_t(X_t)$ and $\dfrac{1}{2}\left( f_t(Y_{t,1})+f_t(Y_{t,2})\right)$ is then determined by the environment (i.e. the property of $f_t$). It is straightforward to bound $| \dfrac{1}{2}\left( f_t(Y_{t,1})+f_t(Y_{t,2})\right)- f_t(X_t)|$ as a function of $\delta$. \todoc{How? When $f_t$ is Lipschitz, smooth, etc? So you mean, when $f_t$ is a smooth function?}
The common assumption for this setting is: The oracle is a stochastic mapping from $(X, \delta, f)$ to $(G, Y)$; The algorithm selects the point $X_t$ depending on $\left( X_1, G_{1,1}, G_{1,2}, \cdots, X_{t-1},G_{t-1,1}, G_{t-1,2}  \right)$. This two-point feedback can be easily extended to multi-point feedback, too.
\fi

In the \emph{stochastic BCO} setting,
the algorithm sequentially chooses the points $X_1,\dots,X_n\in \cK$ while observing the loss function at these points in noise.
In particular, in round $t$, the algorithm chooses $X_t$ based on the earlier observations $Z_1,\dots,Z_{t-1}\in \R$ and $X_1,\dots,X_{t-1}$, after which it observes $Z_t$, where $Z_t$ is the value of $f(X_t)$ corrupted by ``noise''.


Previous research considered several possible constraints connecting $Z_t$ and $f(X_t)$.
One simple assumption is that $Z_t-f(X_t)$ is an $\cF_t = \sigma(X_{1:t},Z_{1:t-1})$-adapted martingale difference sequence (with favorable tail properties).
% \todoc{Some readers might be put off by martingales..}
A specific case is when $Z_t - f(X_t) = \xi_t$, where $(\xi_t)$ is a sequence of independent and identically distributed (i.i.d.) variables.
A stronger assumption, which is most appropriate in stochastic programming,
is that 
\begin{equation}
\label{eq:controlled}
Z_t = F(X_t,\noiseCap_t),
\end{equation} where $\noiseCap_t\in \R$ is chosen by the algorithm and $\EE{F(x,\noiseCap)}=f(X)$ for some distribution $P_{\noiseCap}$ over the reals. That is the algorithm can call the oracle $F(x,\noise)$ by selecting both $x$ and $\noise$. Note that the algorithm is aware of $P_{\noiseCap}$, but does not know how different values of $\noise$ affect the noise $\xi(x,\noise)=F(x,\noise)-f(x)$. Nevertheless, the algorithm can control the noise by selecting $\noiseCap_t$, and hence it can obtain unbiased estimates of the function values by selecting $\noiseCap_t$ from $P_{\noiseCap}$; we will refer to this case as the \emph{controlled noise} setting and to other situations as the case of \emph{uncontrolled noise}. The advantage of the controlled noise setting is that the algorithm may obtain samples of $F$ at $X^+$ and $X^-$, with the same noise levels:
controlling the noise this way helps in improving the accuracy of the estimates and is common in the field of \emph{simulation optimization}
\citep{KlSpNa99,duchi2015optimal}. This is especially useful when the gradient estimate is created from multiple observations, see \eqref{eq:twosp}. Note that creating an estimate from $K$ points (which is equivalent to a multi-point feedback setup where $K$ points are queried in each round) changes the number of rounds from $n$ to $n/K$, and  the reduction in the number of rounds, being a fixed constant factor, is negligible, as far as the convergence rates are considered.


%
% as in the online case.
%
%However, what differs in the optimization variant is that the value of the loss at the points sent to the oracle does not matter.
%Hence, in this setting the distinction between one-point and multi-point feedback (as long as the number observations is fixed, independently of the dimension) is irrelevant:


%A major tool in bandit convex optimization is to design gradient estimators, which are then used in conjunction with variants of gradient descent. \todoc{zillions of references.}
\subsection{Estimating the Gradient}

A common popular idea in bandit convex optimization is to use the bandit feedback to construct noisy (and biased) estimates of the gradient.
In the following, we provide a few examples for oracles that construct gradient estimates for function classes that are increasingly general: from smooth, convex to non-differentiable functions.

\paragraph{One-point feedback}
Given $x\in \cK$, $0<\delta\le 1$, common gradient estimates that are
based on a single query to the function evaluation oracle (the so-called
``one-point feedback'') take the form
\begin{align}
  \label{eq:one-point}
G = \frac{Z}{\delta}V, \textrm{ where } Z = f(x+\delta U) + \xi\,,
\end{align}
where $(U,V)\in \R^d\times \R^d$ are jointly distributed random variables
and $\xi$ is the function evaluation noise (the distribution of $\xi$ may depend on $x+\delta U$) and $G$ is the estimate of $\nabla f(x)$ ($f:\cK\to \R$).

In all oracle constructions we will use the following assumption:
\begin{ass}
  \label{ass:gradbasic}
  Let $\K \subset \D^\circ \subset \R^d$, where $f:\D \to \R$.\footnote{Here, $\D^\circ$ denotes the interior of $\D$.}
  The joint distribution of $(U,V)$ is such that
  for any $x\in \K$, $x+\delta U \in \D$ a.s.,
  $\E[V U\tr] = I$, while
  $\EE{\norm{V}_*^2}$, $\EE{ \norm{U}^3 }<+\infty$.
\end{ass}
Note that here the function domain $\D$ can be larger than or equal to the set $\K$, where the algorithm chooses $x$. This is to ensure that the oracle will not receive invalid inputs, that is, queries where $f$ is not defined.
When the functions are defined over $\K$ only and $\K$ is bounded, the above constructions only work for $\delta$ small enough.
In this case, the best approach perhaps is to use Dikin ellipsoids to construct the oracles, as done by \citet{HaLe14:SOC}.

The next proposition, whose proof is based on ideas from \citet{spall1992multivariate}\todoa{add citation for the convex case} shows that the above one-point gradient estimator leads to a type-I (and, hence, also type-II) oracle under slightly stronger assumptions.

\begin{proposition}
\label{prop:grad-onepoint}
Let $f:\cD \to \R$ and let $\gamma$ be the one-point feedback oracle defined in \eqref{eq:one-point}.
Let \cref{ass:gradbasic} hold.
Assume further that
  $U$ is symmetrically distributed,
  $V = h(U)$, where $h:\R^d \to \R^d$ is an odd function,
  and
  $\EE{V}=0$.
Then $\gamma$ is a type-I oracle with $c_1(\delta)$ and $c_2(\delta)$ defined for the uncontrolled noise case in \cref{tab:oracles}
when $f$ is either convex and $L$-smooth or three times continuously differentiable (in notation: $f \in \C^3$).
% \todoc{Add the convex+smooth case}
\end{proposition}
%\begin{proof}
%See Section \ref{sec:appendix-grad}.
%\end{proof}

\paragraph{One-point feedback with smoothing}
Another possibility is to use the so-called smoothing technique
\citep{PoTsy90,flaxman2005online,HaLe14:SOC}\todoa{ Cs: Is this correct?}
to obtain type-II oracles:


Type-II oracles can be obtained using the same construction as above, but with a different analysis:
\begin{proposition}
\label{prop:flaxman}
Let $f:\cD \to \R$ and let $\gamma$ be the one-point feedback oracle defined in \eqref{eq:one-point}.
Define
\begin{align*}
V = n_W(U)\dfrac{\lvert \partial W\rvert}{\lvert W \rvert}\,,
\end{align*}
where $W \subset \R^n$ is a convex body with boundary $\partial W$, $U$ is uniformly distributed in $\partial W$, $n_W(U)$ denotes the normal vector of $\partial W$ at $U$, and $\lvert \cdot \rvert$ denotes the volume.
Then, if $f$ is Lipschitz, $\gamma$ is a type-II oracle with $c_1(\delta)=C_1 \delta$, $c_2(\delta) = C_2/\delta^2$ for some appropriate constants $C_1,C_2>0$ depending on $W$ and the Lipschitz constant of $f$.
If $f$ is smooth, further assuming $W$ is symmetric w.r.t. the origin, $\gamma$ is a type-I and type-II oracle, with $c_1(\delta) = C'_1\delta^2$, $c_2(\delta) = C'_2/\delta^2$ for some appropriate constants $C_1,C_2>0$ depending on $W$ and the smoothness parameter of $f$.\todoa{Do we need convexity here?}
\end{proposition}
%\begin{proof}
%See Section \ref{sec:appendix-grad}.
%\end{proof}



\paragraph{Two-point feedback}
While the one-point estimators are intriguing, as discussed beforehand,
in the optimization setting one can also always group two consecutive observations and obtain similar smoothing-type estimates 
at the price of reducing the number of rounds by a factor of two only, which has a negligible effect on the rate of convergence.
Next we present an oracle that uses two function evaluations to obtain a gradient estimate.
As will be discussed later, this oracle encompasses several simultaneous perturbation methods (see \citealp{bhatnagar-book}):
Given the inputs $x\in \K$,  $0<\delta\le 1$,
% \todoc{We need an upper bound I believe. Add it earlier.}
the gradient estimate is
\begin{align}
G &=  \dfrac{Z^+ - Z^-}{2\delta}\, V \,, 
 \label{eq:twosp}
\end{align}
where $Z^{\pm} = f(X^{\pm}) + \xi^{\pm}$, $X^{\pm} = x \pm \delta U$, $U,V\in \R^d$, $\xi^{\pm}\in \R$ are random, jointly distributed random variables, $U,V$ chosen by the oracle in the uncontrolled case and chosen by the algorithm in the controlled case
from some fixed distribution characterizing the oracle, and $\xi^{\pm}$ being the noise of the returned feedback $Z^{\pm}$ at points $X^{\pm}$.
For the following proposition we consider $4=2\times 2$ cases.
First, the function is either assumed to be $L$-smooth and convex (i.e., the derivative of $f$ is $L$-Lipschitz w.r.t. $\norm{\cdot}_*$), or it is assumed to be three times continuously differentiable ($f\in C^3$).
The other two options are either the controlled noise  setting of \eqref{eq:controlled}, or, in the uncontrolled case, we make the alternate assumptions
\begin{align}
\E[\xi^+-\xi^- |\, U,V] = 0 \text{~~ and ~~}\nonumber\\
\E [ (\xi^{+} - \xi^-)^{2} \mid V] \le \sigma_\xi^2 <\infty\,.
\label{eq:noiseass}
\end{align}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{table}
\small
\centering
\begin{tabular}{|c|c|c|}
\toprule
\textbf{Noise }$\bm{ \rightarrow}$ & \textbf{Controlled } & \textbf{Uncontrolled } \\
\textbf{Function } &(see~\eqref{eq:controlled})&(see~\eqref{eq:noiseass})\\
$\bm{\downarrow}$ &&\\\midrule
\multirow{2}{*}{\textbf{Convex + Smooth}} & \multirow{2}{*}{$(C_1 \delta, C_2)$} & \multirow{2}{*}{$(C_1\delta, C_2/\delta^2)$}\\
 &&\\\midrule
\multirow{2}{*}{$\bm{f \in \C^3}$} & \multirow{2}{*}{$(C_1 \delta^2, C_2/\delta^2)$} & \multirow{2}{*}{$(C_1 \delta^2, C_2/\delta^2)$} \\
 &&\\\bottomrule
\end{tabular}
\caption{Gradient oracles for different function classes and noise categories. Each table entry specifies the pair $(c_1(\delta), c_2(\delta))$.
For the first row, $C_1 =
\frac{L}{2} \E[ \dnorm{V} \norm{U}^2]$ and
$C_2 =   L^2 (2 + \frac{1}{2}\E\left[ \dnorm{V}^2 \norm{U}^4 \right])$
for the controlled noise and
 $C_2 =  C_{2}^{(u)} \doteq 4 \EE{\norm{V}_*^2}\left( \sigma_\xi^2+\fspan(f)\right)$ for the uncontrolled noise.
For the second row, $C_1 = \frac{B_3 \EE{ \norm{V}_* \norm{U}^3 }}{6}$ and $C_2 =  C_{2}^{(u)}$,
with $B_3 = \sup_{x\in \K} \norm{\nabla^3 f(x)}$, where $\norm{\cdot}$ is the implied norm for rank-3 tensors.
}
\label{tab:oracles}
\end{table}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
The following proposition, whose proof is based on \citep[Lemma~1]{spall1992multivariate} and \citep[Lemma~1]{duchi2015optimal}, provides conditions under which the bias-variance parameters $(c_1,c_2)$ can be bounded as shown in \cref{tab:oracles}:
\begin{proposition}
\label{prop:grad-spsa}
Consider a function $f:\D \to \R$, with $\K \subset \D^\circ \subset \R^d$.%\footnote{Here, $\D^\circ$ denotes the interior of $\D$.}
For any $x \in \cK$, and $0< \delta \le 1$ let the oracle $\gamma$ return $G$ as specified in~\eqref{eq:twosp},
where $(U,V)$ are such that $x+\delta U \in \D$ a.s.,
$\E[V U\tr] = I$, while
$\EE{\norm{V}_*^2}$ and $\EE{ \norm{U}^3 }<+\infty$.
Then $\gamma$ is a type-I oracle with $c_1(\delta)$ and $c_2(\delta)$ given by \cref{tab:oracles}.
\end{proposition}
%\begin{proof}
%See Section \ref{sec:appendix-grad}.
%\end{proof}
\todoc[inline]{I am pretty sure that the bias could be brought down
for two-point feedback, too, using the technique of \cref{prop:flaxman}.
}

\paragraph{Popular choices for $U$ and $V$:}\ \\
\begin{inparaenum}[$\bullet$]
 \item If we set $U_i$ to be independent, symmetric $\pm 1$-valued random variables and $V_i = 1/U_i$, then we recover the popular SPSA scheme proposed by \cite{spall1992multivariate}.
It is easy to see that $\EE{  V U\tr } = I$ holds in this case.
 When the norm $\norm{\cdot}$ is the $2$-norm, $C_1 = O(d^2)$ and $C_2 = O(d)$. If we set $\norm{\cdot}$ to be the max-norm, $C_1 = O(\sqrt{d})$ and $C_2 = O(d)$.\\
 \item If we set $V=U$ with $U$ chosen uniform at random on the surface of a sphere with radius $\sqrt{d}$,
 then we recover the RDSA scheme proposed by  \citet[pp.~58--60]{kushcla}.
 In particular, the $(U_i)$ are identically distributed with $\EE{ U_i U_j } = 0$ if $i\ne j$ and $\EE{ U\tr U } = d$, hence $\EE{U_i^2} = 1$. Thus, if we choose $\norm{\cdot}$ to be the $2$-norm, $C_1 = O( d^2 )$ and $C_2 = O(d)$.\\
 \item If we set $V=U$ with $U$ the standard $d$-dimensional Gaussian with unit covariance matrix, we recover the smoothed functional (SF) scheme proposed by \cite{katkul}.
Indeed, in this case, by definition, $\EE{VU\tr} = \EE{U U\tr } = I$.
When $\norm{\cdot}$ is the $2$-norm, $C_1 = O(d^2)$
%$\norm{U}^4 = (\sum_{i=1}^d U_i^2)^{2} = \sum_i U_i^4 + 2 \sum_{i<j} U_i^2 U_j^2$,
%hence $\EE{ \norm{U}^4} = O(d^2)$
 and $C_2 = O( d)$.
 This scheme can also be interpreted as a smoothing operation that  convolves the gradient of the function $f$ with a Gaussian density.
%  , followed by an integration by parts and the resulting integral can be estimated using samples (without access to the gradient of $f$).
\end{inparaenum}


% If the function $f$ is assumed to be convex and smooth, then gradient estimates similar to \eqref{eq:twosp} can be constructed and this does not require higher order smoothness conditions as in Proposition \ref{prop:grad-spsa}.
% \begin{proposition}
% \label{prop:grad-convex}
% Consider a function $f:\D \to \R$, with $\K \subset \D \subset \R^d$,
% that is convex and has a $L$-Lipschitz continuous gradient. .
% For any $x \in \cK$, and $\delta >0$ such that $\B(x,\delta) \in \D$, let the oracle $\gamma$ return
% \begin{align}
% % Y = x+\delta U \,, \quad
% G =  V \left(\dfrac{f(x+\delta U) + \xi^+ - (f(x-\delta U) + \xi^-)}{2\delta}\right),
%  \label{eq:twosp}
% \end{align}
% where $\xi^+, \xi^-$, $V$, $U$ are as in Proposition \ref{prop:grad-spsa}.
% Then, we have that $\gamma$ is a type-I oracle with $c_1(\delta) = C_1 \delta$ and $c_2(\delta) = C_2 d/\delta^2$.
% \end{proposition}
% \begin{proof}
% See Appendix \ref{sec:appendix-grad}.
% \end{proof}


% A popular idea for estimating gradient using one-point feedback is the smoothed function approach, which was originally proposed in \citep{katkul}. The idea is to convolve the gradient of the objective function with a suitable density function and then, via an integration by parts arguments show that the resulting integral is an estimate of the gradient of the smoothed objective function.
% This approach has been adopted in a stochastic convex optimization setup in \cite{duchi2015optimal}.

%% \paragraph{Simultaneous perturbation methods:}
%The idea of simultaneous perturbation can work even for functions that are not differentiable, as shown in \cite{flaxman2005online}.
%% follow this approach in the context of bandit convex optimization.
%Formally,
%% a $(c_1,c_2)$ Type-II oracle when $\cF$ is a general class of functions (this does not even require differentiability).
%given any $f \in \cF$, $x \in \cK$, and $\delta >0$, the oracle returns\footnote{See also \cite[pp.~58-60]{kushcla} for an old reference that proposed a gradient estimate similar to \eqref{eq:flaxman}.}
%\begin{align}
% Y = x+\delta u \in \cK', \quad
% G = \dfrac{d}{\delta}f(x+\delta u)u \in \R^d, \label{eq:flaxman}
%\end{align}
%where $u\in \R^d$ is a random unit vector, so the first condition of \cref{def:oracle2} immediately follows.
%The variance of $G$ is bounded by $d^2C^2 \delta^{-2}$ for some constant $C = \sup_{y\in \cK'}f(y)$.
%\todox[inline]{Fix this proposition statement to say Flaxman scheme is a type II oracle}
%\begin{proposition}
%Let $\tilde{f}(x) = \EE{f(x+\delta v)}$ denote the smoothed version of $f$. Then, we have
%$\EE{G} = \nabla \tilde{f}(x)$.
%\end{proposition}
%\begin{proof}
% See Lemma 1 in \citep{flaxman2005online}.
%\end{proof}
% As to the bias condition, it was proved that $\EE{G} = \nabla \tilde{f}(x)$, where $\tilde{f}$ is a smoothed version of $f$, i.e.,
%$\tilde{f}(x) = \EE{f(x+\delta v)}$,
%$v$ is a random vector in a unit ball. There are different ways to bound the bias depending on the property of $f$.
%If $f$ is $L_{lip}$-Lipschitz over $\cK'$, then we have
%\begin{align*}
%\MoveEqLeft
%\norm{\tilde{f}(x)-f(x)}_\infty \\
%=&\norm{\EE{f(x+\delta v)-f(x)}}_\infty
%\le L_{lip} \delta \,.
%\end{align*}
%If $f$ is convex, and $L_{smo}$-smooth,
%\begin{align*}
%\MoveEqLeft
%\norm{\tilde{f}(x)-f(x)}_\infty \\
%\le& \norm{\EE{\ip{\nabla f(x), \delta v}+\dfrac{L_{smo}}{2}\delta^2\norm{v}^2}}_\infty\\
%\le &\dfrac{L_{smo}}{2}\delta^2 \,.
%\end{align*}
%Therefore, the estimator \eqref{eq:flaxman} can always fit the oracle setting by choosing $c_1(\delta) = C_1 \delta$ (or $C_1\delta^2$), $c_2(\delta) = C_2 \delta^{-2}$, for some constant $C_1$, $C_2$.

% \begin{remark}
%  Instead of picking $u$ randomly on the surface of a unit sphere, one can employ an random variable $u$ that satisfies $E[u u\tr] = I_d$, where $I_d$ is the $d$-dimensional identity matrix. A popular choice for $u$ that satisfies the aforementioned constraint is the $d$-dimensional standard Gaussian - a choice that has been explored in the context of zeroth order optimization in \citep{duchi2015optimal}. See \citep{bhatnagar-book} for an overview of gradient and Hessian estimation techniques using random perturbations.
% \end{remark}


\subsection{Achievable Results for Stochastic BCO}
We now consider stochastic BCO with $L$-smooth functions over a convex, closed non-empty domain $\K$. \todoc{Check that $K$ is always assumed to be closed. Otherwise the optimum may not belong to $K$.}\todoa{Duchi et al (2015) assumes closed functions.}
Let $\cF$ denote the set of these functions.
\cite{duchi2015optimal} proves that the minimax expected optimization error
for the functions $\cF$ with uncontrolled noise is lower bounded by $\Omega(n^{-1/2})$. \todoc{We should sort out dimension dependences later.}
They also give an algorithm which uses two-point gradient estimates which matches this lower bound for the case of \emph{controlled noise}.
For controlled noise, the constructions in the previous section give that for two-point estimators $c_1(\delta) = C_1 \delta^p$ and $c_2(\delta) = C_2\delta^{-q}$ with $p=1$ and $q=0$. Plugging this into
\cref{thm:ub} we get the rate $O(n^{-1/2})$ (which is unsurprising
given that the algorithms and the upper bound proof techniques are essentially the same as that of \citealp{duchi2015optimal}).
However, when the noise is uncontrolled, the best that we get is $p=1$ and $q=2$ (if, in addition, $f\in \C^3$, then we get $p=2$, $q=2$).\todoa{Is this "in addition"?}
From \cref{thm:lb-convex} we get that with such oracles, no algorithm can get better rate than $\Omega(n^{-1/4})$ (resp., $\Omega(n^{-1/3})$), while from
\cref{thm:ub} we get that these rates are matched by mirror descent.
We can summarize these findings as follows:
\todoc{Can we show that no better oracles exist?}
\begin{theorem}\label{thm:aaab}
Consider $\F_{L,0}$, the space of convex, $L$-smooth functions over a convex, closed non-empty domain $\K$.
Then, we have the following:\\
\textit{\textbf{Uncontrolled noise}}:
Take any $(\delta^1,\delta^{-2})$ type-I oracle $\gamma$.
There exists an algorithm that uses $\gamma$
and achieves the rate $O(n^{-1/4})$.
Furthermore, no algorithm using $\gamma$
 can achieve better error than $\Omega(n^{-1/4})$ for every $(\delta^1,\delta^{-2})$ type-I oracle $\gamma$.\\
\textit{\textbf{Uncontrolled noise}, $f\in \C^3$}:
Take any $(\delta^2,\delta^{-2})$ type-I oracle $\gamma$.
There exists an algorithm that uses $\gamma$
and achieves the rate $O(n^{-1/3})$.
Furthermore, no algorithm using $\gamma$
 can achieve better error than $\Omega(n^{-1/3})$ for every $(\delta^2,\delta^{-2})$ type-I oracle $\gamma$.\\
\textit{\textbf{Controlled noise}}:
Take any $(\delta,1)$ type-I oracle $\gamma$.
There exists an algorithm that uses $\gamma$ an
achieves the rate $O(n^{-1/2})$.
Furthermore, no algorithm using $\gamma$
 can achieve better error than $\Omega(n^{-1/2})$ for every $(\delta,1)$ type-I oracle $\gamma$.
\end{theorem}

For stochastic BCO with uncontrolled noise, \cite{AgFoHsuKaRa13:SIAM} analyze a variant of the well-known ellipsoid method and provide regret bounds for the case of convex, $1$-Lipschitz and bounded functions on $[0,1]$. Their regret bound implies a minimax error \eqref{eq:minimaxerrdef} bound of order  $O\left(\sqrt{d^{32}/n}\right)$.
%\todoc{Not for this setting! This paper should be mentioned in the previous section actually. For this setting, we  do not have \emph{any} algorithms that would achieve $O(n^{1/2})$.}
\cite{liang2014zeroth} provide an algorithm based on random walks (and not using gradient estimates) for the setting of convex, bounded functions whose domain is contained in the unit cube and their algorithm results in a bound of the order $\O\left((d^{14}/n)^{1/2}\right)$ for the minimax error.
%\todoc{What are the conditions for their theorem? Boundedness? Lipschitzness? Or nothing?}
%This algorithm achieves an upper bound of $\O\left((d^{14}/n)^{1/2}\right)$,
These bounds decrease faster in $n$ than the bound available in Theorem \ref{thm:aaab}, while showing a much worse dependence on the dimension.\todoc{We should show the dimension dependence in the result to make this point. This should be shown for the same setting as the one considered by \cite{liang2014zeroth}.}
However, what is more interesting is that our results also shows that an $O(n^{-1/2})$ upper bound \emph{cannot} be achieved solely based on the oracle properties of the gradient estimates considered. Since all gradient algorithms for stochastic BCO in the literature use gradient estimates we consider with an analysis that only uses the above oracle properties of the methods, it is no wonder that the best known upper bound for convex+smooth functions is $O(n^{-1/3})$ \citep{saha2011improved}.

The above result also shows that the gradient oracle based algorithms are optimal for smooth problems, under a controlled noise setting.
While \cite{duchi2015optimal} suggests that it is the power of two-point gradient estimators that help to achieve this, we need to add that a critical condition to achieve the optimal rate is that the noise must be controlled. 

Finally, let us make some remarks on the early literature on this problem.
A finite time lower bound for stochastic, smooth BCO is presented by  \citet{Chen88:LB-AoS} for
convex functions on the real line.
While the lower bound is stated for $r$-smooth functions with $r$ odd (these are functions $f$ with $\norm{f^{(r)}}_{\infty}\le L$), and $r$ greater than one, careful checking of the results show that nor $r>1$, neither that $r$ must be odd is ever used in the proof.
Hence, the result holds for $r\ge 2$.
The lower bound presented for a given value of $r$ takes the form $\Omega( n^{ -(r-1)/(2r)} )$. For $r=2$ (which approximately corresponds to the smooth case), we get $\Omega(n^{-1/4})$, while for $r=3$ (which is ``almost'' the same as $f\in \C^3$), one gets $\Omega(n^{-1/3})$.
While these match the bounds in \cref{thm:aaab}, they are larger than the error achieved by
the algorithm of \cite{liang2014zeroth}. The resolution of the apparent contradiction is that the lower bounds of \citet{Chen88:LB-AoS} concern distance to the optimum (i.e., $\EE{ \norm{\hat{X}_n - x^* }}$), while the optimization error is defined in terms of the objective function gap $\EE{ f(\hat{X}_n) -f( x^*)}$.
Similar results are obtained by \citet{PoTsy90}, who also considered distance to the optimum and proved that mirror descent with gradient estimation achieves asymptotically optimal rates for these settings.

\todoc{Cite all the other papers, summarizing what they achieve. }

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "bgo"
%%% End:
