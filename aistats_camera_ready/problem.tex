%!TEX root =  bgo-cam-ready.tex
% please do not delete or change the first line (needed by Csaba's editor)

\textit{Notation:} Capital letters will denote random variables.
For $i\le j$ positive integers,
 we use the notation $a_{i:j}$ to denote
 the sequence $(a_i,a_{i+1}, \dots, a_{j})$.
 We let $\| \cdot \|$ denote some norm on $\R^d$, whose dual is denoted by $\dnorm{\cdot}$. 
 Let $\K \subset \R^d$ be a non-empty closed convex  set. 
 Given the function $f:\K \to \R$ which is differentiable\todoa{I have removed the comment about generalization to subgradients. If the function is not differentiable, how could it be smooth?}%
%\footnote{Here we assume the differentiablity for simplicity of definition, actually it is easy to generalize to non-differentiable functions by using sub-gradient.} 
  in $\K^\circ$,%
  \footnote{For $A\subset \mathbb{R}^d$, $A^\circ$ denotes the interior of $A$.}\todoa{Shouldn't it be relative interior?}
 $f$ is said to be $\mu$-strongly convex w.r.t.\  $\| \cdot \|$  ($\mu\ge 0$) if
 $\tfrac{\mu}{2} \|x-y\|^2 \le \mathcal{D}_f(x,y)\doteq f(x)-f(y)-\ip{\nabla f(y),x-y}$, for all $x \in \K \,, y \in \K^\circ$.
Similarly, $f$ is $\mu$-strongly convex w.r.t.\  a \emph{function} $\cR$
	if $\tfrac{\mu}{2}\DR(x,y)\le\mathcal{D}_f(x,y)$ for all $x \in \K \,, y \in \K^\circ$, where $\cK^\circ\subseteq \dom(\mathcal{R})$ and $\mathcal{R}$ is differentiable over $\K^\circ$.
 A function $f$ is $L$-smooth w.r.t.\  $\| \cdot \| $ for some $L>0$ if
 %$f(x) \le f(y) + \ip{\nabla f(y), y-x} +
$D_f(x,y) \le \tfrac{L}{2} \|x-y\|^2$, for all $x \in \K \,, y \in \K^\circ$.
 This latter condition is equivalent to that $\nabla f$ is $L$-Lipschitz, that is, 
 $\norm{\nabla f(x) - \nabla f(y)}_* \le L \norm{x-y}$ \citep[Theorem~2.1.5]{nesterov2004introductory}.
% \todoc{Add citation}
 We let $\F_{L,\mu, \cR}(\K)$ denote the class of functions that are $\mu$-strongly convex w.r.t. $\cR$ and $L$-smooth w.r.t. some norm $\norm{\cdot}$ on the set $\K$ (typically, we will assume that $\cR$ is also strongly convex w.r.t. $\norm{\cdot}$).
 Note that $\F_{L,\mu,\cR}(\K)$ includes functions whose domain is larger than or equal to $\K$.
We also let $\F_{L,\mu}(\K)$ be $\F_{L,\mu,\cR}(\cK)$ with $\cR(\cdot) = \frac12 \norm{\cdot}_2^2$.
Then, the set of convex and $L$-smooth functions with domain including $\K$ is  $\F_{L,0}(\K)$.
Besides the standard big-Oh\todoa{$O(\cdot)$ instead?} notation, we will also use $\tilde{O}(\cdot)$:
For a positive valued function $f: \mathbb{N} \to \R_+$, $\tilde{O}(f)$ contains any $g:\N \to \R_+$ such that
$g =O( \log^p(n) f(n) )$ for some $p>0$.
(As usual, we abuse notation by writing $g= O(f)$ instead of $g\in O(f)$.)
 %Furthermore, let $\F_{L,\mu,\cR}(\K)$ denote the set of functions that are  $L$-smooth and $\mu$-strongly convex w.r.t.\  $\cR$. \todoc{Are these $L$-smooth w.r.t. $\cR$? This is a bit confusing.}
% We let $\normal(0, I)$ denote the standard normal distribution in $d$-dimensions. 
% \todoc{I am pretty sure $\normal(0, I)$ is not used in the main text, hence commenting it out. We will need to define it for the full version!!!}
Finally, we will denote the indicator function of an event $E$ by $\indic{E}$, that is $\indic{E}=1$ if $E$ holds and equals zero otherwise.
\begin{figure}
\begin{center}
%\vspace{-0.1cm}
\includegraphics[width=0.8\textwidth]{../figs/oracle}
\end{center}
%\vspace{-0.6cm}
\caption{The interaction of the algorithms with the gradient estimation oracle and the environment. For more information, see the text. \vspace{-0.3cm}}
\label{fig:oracle}
\end{figure}

In this paper, we consider convex optimization in a novel setting, both for stochastic as well as online BCO.
%More specifically, we consider both an online learning setting and an optimization setting.
In the online BCO setting, the environment chooses a sequence of loss functions $f_1,\dots,f_n$ belonging to a set $\cF$ of convex functions over a common, non-empty convex closed domain $\cK\subset \R^d$.
In the stochastic BCO setting, a single fixed loss function $f\in \cF$ is chosen.
An algorithm chooses a sequence of points $X_1,\dots,X_n\in \cK$ in a serial fashion.
The novelty of our setting is that the algorithm, upon selecting point $X_t$, receives
a noisy and potentially biased estimate $G_t\in \R^d$
of the gradient of the loss function $f$
(more generally, an estimate of a subgradient of $f$, in case $f$ is not differentiable at $X_t$).
To control the bias and the variance, the algorithm can choose a \emph{tolerance parameter} $\delta_t>0$
(in particular, we allow the algorithms to choose the tolerance parameter sequentially).
A smaller $\delta_t$ results in a smaller ``bias'' (for the precise meaning of bias, we will consider two definitions below), while typically with a smaller $\delta_t$, the ``variance'' of the gradient estimate increases.
Notice that in the online BCO setting, the algorithm suffers the loss $f_t(Y_t)$ in round $t$, where $Y_t\in \cK$\footnote{For simplicity, in some cases we allow $f$ to be defined outside of $\K$ and allow $Y_t$ to be in a small vicinity of $\K$.} is guaranteed to be in the $\delta_t$-vicinity of $X_t$.
%While this point is not relevant in the optimization setting, in the online learning setting,
The goal in the online BCO setting is to minimize the expected \emph{regret}, defined as follows:
	$$R_n =\EE{ \sum_{t=1}^n f_t(Y_t)} - \inf_{x\in \cK} \sum_{t=1}^n f_t(x).$$
In the stochastic BCO setting, the algorithm is also required to select a point $\hat{X}_n\in \cK$ once
the $n$th round is over (in both settings, $n$ is given to the algorithms)
and the algorithm's performance is quantified using the \emph{optimization error}, defined as
$$\Delta_n = \EE{f(\hat{X}_n)} - \inf_{x\in \cK} f(x).$$

The main novelty of the model is that the information flow between the algorithm and the environment (holding $f$, or $f_{1:n}$) is mediated by a stochastic gradient estimation oracle. As we shall see, numerous existing approaches to online learning and optimization based on noisy pointwise information fit in this framework.

We will use two classes of oracles. In both cases, the oracles are specified by
two functions $c_1,c_2:[0,\infty)\to [0,\infty)$, which will be assumed to be continuous,
monotonously increasing (resp., decreasing) with
$\lim_{\delta\to  0} c_1(\delta)=0$ and $\lim_{\delta\to 0} c_2(\delta)=+\infty$.
Typical choices for $c_1,c_2$ are $c_1(\delta) = C_1 \delta^p$, $c_2(\delta) = C_2\delta^{-q}$ with $p,q>0$.
Our type-I oracles are defined as follows:
%The relationship between these oracles will be studied in \cref{sec:orrel}.
%\todoc{$Y$ should be removed completely, and added only when online learning is considered.}
%\vspace{-0.2cm}
\begin{definition}[$(c_1,c_2)$ type-I  oracle]
\label{def:oracle1}
We say that $\gamma$ is a  $(c_1,c_2)$ type-I oracle for $\cF$, if for any function $f\in \cF$,
$x\in \cK,0<\delta\le 1$, $\gamma$ returns random elements  $G\in \R^d$ and  $Y\in \cK$ such that
$\norm{x-Y}\le \delta$ almost surely (a.s.) and the following hold:
%\vspace{-0.2cm}
\begin{enumerate}
%\item $\norm{x-Y}\le \delta$ almost surely (a.s.);
\item $\norm{ \EE{G}  - \nabla f(x)  }_* \le c_1(\delta) $ (bias); and
\item $\EE{\norm{ G -  \EE{G} }_*^2} \le c_2(\delta)$ (variance).
\end{enumerate}
%\vspace{-0.1cm}
\end{definition}
The upper bound on $\delta$ is arbitrary: by changing the norm, any other value can also be accommodated. Also, the upper bound only matters when $\K$ is bounded and the functions in $\cF$ are defined only in a small vicinity of $\K$.
%\todoc[inline]{For precision, we should take conditional expectations given the past in the above definitions.}

The second type of oracles considered is as follows: 
%\todoa{Here we could distinguish between the class of $f$ and $\tf$: we basically do not need to assume anything about $f$ as long as $\tf$ belongs to a nice enough family.}
\begin{definition}[$(c_1,c_2)$ type-II  oracle]
\label{def:oracle2}
We say that $\gamma$ is a  $(c_1,c_2)$ type-II oracle for $\cF$, if for any function $f\in \cF$,
$x\in \cK,0<\delta\le 1$, $\gamma$ returns $G\in \R^d$ and  $Y\in \cK$ random elements such that $\norm{x-Y}\le \delta$ a.s. and the following hold:
%\vspace{-0.2cm}
\begin{enumerate}
%\item $\norm{x-Y}\le \delta$ a.s.;
\item There exists $\tilde{f} \in \cF$ such that
$\bignorm{\tilde{f}- f}_\infty \le c_1(\delta)$  and
$\EE{G}  = \nabla \tilde{f}(x)$ (bias); and
\item $\EE{\norm{ G -  \EE{G} }_*^2} \le c_2(\delta)$ (variance).
\end{enumerate}
%\vspace{-0.1cm}
\end{definition}
We will denote the set of type-I (type-II) oracles satisfying the $(c_1,c_2)$-requirements given a function $f\in \cF$ by $\Gamma_1(f,c_1,c_2)$ (resp., $\Gamma_2(f,c_1,c_2)$).

Note that while a type-I oracle returns a biased, noisy gradient estimate for $f$, 
a type-II oracle returns an unbiased, noisy gradient estimate for some function $\tilde{f}$ which is close to $f$.
Note that $\tilde{f}$ is allowed to change with the inputs (not only by $f$, but also with $x$ and $\delta$) in the definition.
In fact, the oracles (in both cases)  can have a memory of previous queries and depending on the memory
can respond to the same inputs $(x,\delta,f)$ with a differently constructed pair.%
\footnote{For oracles with memory, in the definition (and in the proofs provided later in the paper) the expectation should be replaced with
an expectation that is conditioned on the past.}
The oracles that we use will nevertheless be memoryless.

As noted above, even a memoryless type-II oracle can respond such that $\tilde{f}$ depends on $x$ or $\delta$.
A type-II oracle is called a \emph{uniform} type-II oracle if $\tilde{f}$ only depends on $f$ (and possibly the history of previous queries), but not on $x$ and $\delta$.
The type-II oracles that will be explicitly constructed will be all uniform.
%An alternative to the bias condition for type-II oracles, which will also be considered later, is to replace the condition $\norm{\tilde{f}-f}_\infty \le c_1(\delta)$ with%
%\footnote{
%This definition requires the function $f$ to be differentiable. When the functions in $f$ are not differentiable, it is possible
%to modify the definitions to use subgradients. For simplicity, we will not consider this here.
%}
%\begin{align}
%\label{eq:oracle2alt}
%\norm{\nabla \tilde{f}- \nabla f}_* \le c_1(\delta)
%\end{align}
%We call the resulting oracles type-IIb.
%

We call an oracle (type-I or II)  \emph{unbiased} if $\EE{Y}=x$ in the above definitions. Note that if the oracle is unbiased and the loss function is smooth,
 an algorithm does not loose too much from suffering loss at $Y$ instead of the query point $x$
 since in this case, we have 
$$\EE{f(Y)}-f(x) \le \EE{\ip{\nabla f(x), Y-x}+\tfrac{L}{2}\norm{Y-x}^2} \le L\delta^2/2.$$

% \todoc{In fact, I am not sure which definition we should use. So things might change here.}
Examples of specific oracle constructions will be given in  Section~\ref{sec:sbco}. We also note that for type-II oracles we only need properties of the function class which the surrogate function $\tilde{f}$ belongs to, the assumption $f \in \F$ is only included to simplify the definition (e.g., some oracles work for non-convex functions $f$ for which a suitable convex surrogate and the associated oracle exists).

As the next result shows, type-I and II oracles are closely related.
In particular, a type-I oracle is also a type-II oracle (although not a uniform type-II oracle). On the other hand, type-II oracles need to satisfy an alternative condition to become type-I oracles as the closeness of $\tilde{f}$ and $f$ is insufficient to conclude anything about the distance of their gradients:
\begin{proposition}\label{thm:typered}
Definition~\ref{def:oracle1} is a sufficient condition for Definition~\ref{def:oracle2}, given a bounded $\cK$. 
In particular, letting $R = \sup_{y \in \cK}\norm{y}$, 
for any $f,c_1,c_2$ such that $f+\ip{c,\cdot} \in \F$ for any $\norm{c}_* \le c_1(1)$, it holds that $\Gamma_1(f,c_1,c_2) \subset \Gamma_2(f,Rc_1,c_2)$. 
Furthermore, if $\bignorm{\tilde{f}-f}_\infty \le c_1(\delta)$ is replaced by 
\begin{align}
\label{eq:oracle2alt}
%\sup_{x\in \cK}
\bignorm{\nabla \tilde{f}- \nabla f}_* \le c_1(\delta)
\end{align}
in Definition~\ref{def:oracle2} (for all $x\in\cK$ and $0<\delta \le 1$), then any oracle satisfying this modified definition  is also a $(c_1,c_2)$ type-I oracle.
\end{proposition}

\begin{proof}
We prove only the first part of the claim, as the second part follows by Definitions~\ref{def:oracle1}--\ref{def:oracle2} and condition \eqref{eq:oracle2alt}.
 %is immediate from the definitions, hence it remains to prove the first part.
Let $\gamma$ be  a $(c_1,c_2)$ type-I oracle. Fix $x$, $\delta,f$ and let the oracle's response be $G,Y$. 
Define $\tilde{f}:\cK \to \mathbb{R}$ by
\[\tilde{f}(y) =\EE{ f(y)+ \ip{G-\nabla f(x) , y}},\]
where the expectation is over the randomness of $G$ (note that $\tilde{f}$ depends on $x$ and $\delta$).
Then, $\nabla \tilde{f}(y) =  \nabla f(y)-\nabla f(x) + \EE{G}$
and thus substituting $x$ for $y$ we get that $\nabla \tilde{f}(x) = \EE{G}$.
Further, 
using $\norm{ \EE{G}  - \nabla f(x)  }_* \le c_1(\delta) $,
we have, for any $y \in \cK$,
\begin{align*}
|\tilde{f}(y)-f(y)|
=
\left| \EE{\ip{G-\nabla f(x), y}}\right|
 \le \largenorm{\EE{G}-\nabla f(x)}_* \, \norm{y}
 \le  R\,c_1(\delta)\,.
\end{align*}
From the above, it follows that $\gamma$ is also an $(Rc_1,c_2)$ Type-II oracle, since $\tilde{f}\in\F$ by the conditions of the proposition. 
\end{proof}

In the online convex optimization setting,
algorithms are compared based on their minimax \emph{regret}, 
whereas in the stochastic convex optimization setting, the algorithms are compared based on their
 minimax \emph{error}
 (sometimes, also called as the ``simple regret'').
Both regret notions are defined with respect to a class of loss functions $\cF$, and the bias/variance control functions $c_1,c_2$.
The \emph{worst-case regret} of algorithm $\A$ interacting with $(c_1,c_2)$ type-I oracles for the function class $\F$ is
defined as
\begin{align*}
%\MoveEqLeft
R_{\F,n}^\cA(c_1,c_2)
&=  \sup_{f_{1:n}\in \cF^n}
	\sup_{\substack{\gamma_t \in \Gamma_1(f_t,c_1,c_2)\\1\le t \le n
	}} R_n^{\cA}(f_{1:n},\gamma_{1:n})
%\label{eq:minimaxregdef}
%\\
%\MoveEqLeft
%= \inf_{\cA} \sup_{f_{1:n}\in \cF}
%	\sup_{\substack{\gamma_t \in \Gamma_1(f_t,c_1,c_2)\\1\le t \le n}}
%\EE{ \sum_{t=1}^n f_t(Y_t) }
%%%%%%& \qquad \qquad \qquad \qquad \qquad
%-\inf_{x\in \cK} \sum_{t=1}^n f_t(x)\,,\\
\end{align*}
where $R_n^{\cA}(f_{1:n},\gamma_{1:n})$ denotes the expected regret of $\cA$ (against $f_{1:n},\gamma_{1:n}$), and
the \emph{minimax expected regret} for $(\cF,c_1,c_2)$ with type-I oracles is defined as
\[
R_{\F,n}^*(c_1,c_2) = \inf_{\cA} R_{\F,n}^\cA(c_1,c_2),
\]
where $\cA$ ranges through all algorithms that interact with the loss sequence  $f_{1:n}= (f_1,\dots,f_n)$
through the oracles $\gamma_{1:n}$ (in round $t$, oracle $\gamma_t$ is used).
The minimax regret for type-II oracles is defined analogously.
% (in what follows we only define these quantities for type-I oracles, as the extension \todoc{Is extension the right word?}
% to type-II oracles is immediate).


In the stochastic BCO setting, the \emph{worst case error} is defined through
\begin{align}
\label{eq:minimaxerrdef}
\Delta_{\F,n}^\cA(c_1,c_2)
= \sup_{f \in \cF} \sup_{\gamma\in \Gamma_1(f,c_1,c_2)}  \Delta_n^{\cA}(f,\gamma)\,, %(f,\gamma)\,,
% \EE{ f(\hat{X}_n) } - \inf_{x\in \cK}  f(x)\,,
\end{align}
where $\Delta_n^{\cA}(f,\gamma)$ is the optimization error that $\cA$ suffers
after $n$ rounds of interaction with $f$ through (a single) $\gamma$ as described earlier, and the \emph{minimax error}
is defined as
\[
\Delta_{\F,n}^*(c_1,c_2) =  \inf_{\cA} \Delta_{\F,n}^\cA(c_1,c_2),
\]
where, again, $\cA$ ranges through all algorithms that interact with $f$ through an oracle.
The minimax error for type-II oracles is defined analogously.


Consider now the case when the set $\K$ is bounded and, in particular, assume that 
$\K$ is included in the unit ball w.r.t. $\norm{\cdot}$.
Assume further that the function set $\F$ is invariant to linear shifts
(that is for any $f\in \F$, $w\in \R^d$, $x\mapsto f(x) + \ip{x,w}$ is also in $\F$).
Let
 $\Delta_{n}^{\mathrm{type-I}}$ and $\Delta_{n}^{\mathrm{type-II}}$ denote  the appropriate minimax errors for the two types of oracles.
Then, by the construction in  Theorem~\ref{thm:typered},
\begin{align}
\Delta_{\F,n}^{\mathrm{type-I}}(c_1,c_2) \le \Delta_{\F,n}^{\mathrm{type-II}}(Rc_1,c_2)\,.
\end{align}
%As a result, when proving lower bounds, we shall consider type-I, while when proving upper bounds we will consider type-II oracles.
Note that $R$ may depend on the dimension $d$, e.g., for $\mathcal{K} = \left[ -1,1 \right]^d$, $R = \sqrt{d}$ when using the Euclidean norm. To clarify the different $c_1$ used by type-I and II oracles, we will present the upper and lower bounds separately for the two oracle tyopes, although the type-I upper bound can actually be derived from type-II (and the type-II lower bound can be derived from type-I). \todoa{There are some issues with assuming closedness under linear shifts. Less is enough, however, see how I changed the proposition, but it only gives guarantees for non-uniform type-II oracles...}
%\todox{I mentioned the different $c_1$  here.}
Also note that for either type of oracles, $\Delta_{\F,n}^*(c_1,c_2) \le R_{\F,n}^*(c_1,c_2)/n$. This follows by the well known construction that turns an online convex optimization method $\A$ for regret minimization into an optimization method by running the method and at the end choosing $\hat{X}_n$ as the average of the points $X_1,\dots,X_n$ queried by $\A$ during the $n$ rounds.
Indeed, then $f(\hat{X}_n) \le \frac1n \sum_{t=1}^n f(X_t)$ by Jensen's inequality, hence the average regret of $\A$ will upper bound the error of choosing $\hat{X}_n$ at the end.
A consequence of this relation is that a lower bound for $\Delta_{\F,n}^*(c_1,c_2) $ will also be a lower bound for $R^*_{\F,n}(c_1,c_2)/n$ and an upper bound on $R^*_{\F,n}(c_1,c_2)$ leads to an upper bound on $\Delta_{\F,n}^*(c_1,c_2)$. This explains why we allowed taking supremum over time-varying oracles in the definition of the regret and why we used a static oracle for the optimization error: to maximize the strength of the bounds we obtain.

%$\hat{X}_n$ is the point returned by $\cA$ after $n$ rounds of interaction which work as described earlier.
