%!TEX root =  bgo-cam-ready.tex
% please do not delete or change the first line (needed by Csaba's editor)
In the current era of big data, gradient based convex optimization methods are more popular than ever. Several models are considered in the literature, with using different type of gradient information, from accessing the full gradient to constructing gradient estimates only from observing samples from the target function (see, e.g., \citealp{nesterov2004introductory,DeGliNe14,HaLe14:SOC,PoTsy90,flaxman2005online,AbHaRa08,AgDeXi10,Ne11:TR,AgFoHsuKaRa13:SIAM,katkul,kushcla,spall1992multivariate,spall1997one,Dip03:AoS,bhatnagar-book,duchi2015optimal}). In this paper, we present and analyze a general framework of convex optimization with biased gradient oracles, which encompasses several models considered before.

In this model, and optimization algorithm can query the oracle repeatedly, and the oracle returns a noisy version of the gradient (or a subgradient for non-differentiable functions) in the vicinity of the query point. More specifically, the distance to the query point, as well as the bias and variance of the returned gradient estimate are guaranteed to be bounded. Gradient oracles have been considered in the literature before \citep{dAsp08,Baes09,SchRoBa11,DeGliNe14}. The main feature of our model is that we allow stochastic noise (and bias), while most of the previous work assumes that the accuracy requirements hold with probability one, or considers adversarial noise. Our gradient oracle model applies to several gradient estimation techniques extensively used in the literature, mostly for the case when the gradient is estimated only based on noisy observations from the target function \citep{katkul,kushcla,spall1992multivariate,spall1997one,Dip03:AoS,bhatnagar-book,duchi2015optimal}. A particularly interesting application of our model is bandit convex optimization, where the algorithm can only query a single function value in each round, contaminated with noise \citep{PoTsy90,flaxman2005online,AbHaRa08,AgDeXi10,Ne11:TR,AgFoHsuKaRa13:SIAM,HaLe14:SOC}. As it turns out, one can construct gradient oracles we consider that capture the bias-variance properties of the gradient estimates used in the above papers, reducing the analysis to our problem. Furthermore, previous practical attempts to bandit convex optimization are all centered around constructing gradient estimates that fit our model.
%((some issues with whether you can cancel the noise; we assume you cannot))A

In this paper we consider the optimization accuracy in both the stochastic and online bandit convex optimization (BCO) setting.
In the stochastic BCO setting, an algorithm repeatedly queries the oracle at different points in order to minimize the optimization error. On the other hand, in the online BCO setting, the aim is to minimize the regret, which roughly translates to ensuring that the sum of the function values is not too far from the optimal value (see Section \ref{sec:sbco} for a detailed description).
We  provide upper and lower bounds on the minimax optimization error (or regret) for several oracle models quantifying the bias-variance tradeoff of the gradient estimate. In particular, we provide matching upper and lower bounds for optimizing smooth, convex functions. We do not claim to invent methods for proving upper bounds as these methods have been developed for special cases for a long time by now (see the references above).
Our main contribution lies in abstracting away the properties of gradient estimation procedures
to create our new oracle model, in which we are able to study not only upper bounds, but also lower bounds about the rate of convergence
(earlier work of \citealt{Chen88:LB-AoS} considered a related lower bound on the converge of the iterate instead of the function value).
Note that our oracle model does not capture the full strength of the gradient estimates used in previous work, but it fully describes the properties of the estimates that are used in their analysis.
As a consequence, our lower bounds show that the known minimax regret of $\sqrt{T}$ \citep{BubeckDKP15,BuEl15}
of online and stochastic bandit convex optimization\todoa{add reference to stochastic} cannot be achieved by the current analysis techniques of the currently used gradient estimation procedures, and our lower bounds even invalidate the claimed weaker upper bound of \cite{DeElKo15}.
%Hence, an interesting corollary to our results is that algorithms which are purely based on gradient estimation will not be able to achieve the minimax regret in online bandit convex optimization using the current proof techniques.

%The rest of the paper is organized as follows: The problem is introduced in \cref{sec:problem}. Our upper and lower bounds on the minimax error are presented in \cref{sec:results}. Sections \ref{sec:sbco}--\ref{sec:obco} describe applications to stochastic and online BCO , respectively. Related general gradient oracle models are discussed in detail in \cref{sec:related}, while proofs are given in \cref{sec:proofs}.

The oracle model is introduced in Section~\ref{sec:problem}. The main upper and lower bounds are provided in Section~\ref{sec:results}, with applications to online and stochastic BCO in Sections~\ref{sec:obco} and~\ref{sec:sbco}. All proofs can be found in the extended version of the paper \citep{HuPrGySz16long}.


\todoc[inline]{Check out the book Stochastic Adaptive Search for Global Optimization by Zabinsky (2003, Springer).
It has results for convex and nonconvex, smooth, zeroth order optimization, with no noise in the observations. 
}

\if0
strongly convex


Bandit convex optimization:

Online adversarial setting. Optimal rate is $\Theta(\sqrt{T})$.
No one knows general practical algorithms achieving this rate.
Strongly convex + smooth: \cite{hazan2014bandit}

Stochastic optimization setting: ??? Shamir's paper \cite{shamir2012complexity}??
Lower bounds, upper bounds for the general case?
\cite{hazan2014bandit} for upper bound.

All kind of papers about how to estimate gradients going back to maybe 70s in Russia.

One-point: \cite{flaxman2005online}

Two-point: \cite{AgDeXi10}

Lower bds: \cite{raginsky2011information} \cite{Chen88:LB-AoS}

Ellipsoid: \cite{AgFoHsuKaRa13:SIAM}



 framework
What is the problem? (New problem: Convex Optimization with Biased Gradient Oracles)
What are the results? Matching lower and upper bounds (several oracle models and relation between them; cumulative regret and optimization error (aka simple regret) and relation between them -- this is mostly known; we consider both constrained, unconstrained)
Why should we care?
Reason 1: For bandit convex optimization we can construct these oracles and reduce to this problem.
Reason 2: Previous practical attempts for bandit convex optimization are all centered around such gradient estimates.
((some issues with whether you can cancel the noise; we assume you cannot))

Main message: Everyone was trying to get better rates with these algorithms (e.g., open question whether in the smooth case you can get better rates for these algorithms -- now we see this is not possible).
\fi
