%!TEX root =  bgo.tex
% please do not delete or change the first line (needed by Csaba's editor)
In the current era of big data, gradient based convex optimization methods are more popular than ever. Several models are considered in the literature, with using different type of gradient information, from accessing the full gradient to constructing gradient estimates only from observing samples from the target function (see, e.g., \citealp{nesterov2004introductory,DeGliNe14,HaLe14:SOC,PoTsy90,flaxman2005online,AbHaRa08,AgDeXi10,Ne11:TR,AgFoHsuKaRa13:SIAM,katkul,kushcla,spall1992multivariate,spall1997one,Dip03:AoS,bhatnagar-book,duchi2015optimal}). In this paper, we present and analyze a general framework of convex optimization with biased gradient oracle, which encompasses several models considered before.

In this model, and optimization algorithm can query the oracle repeatedly, and the oracle returns a noisy version of the gradient (or a subgradient for non-differentiable functions) in the vicinity of the query point. More specifically, the distance to the query point, as well as the bias and variance of the returned gradient estimate are guaranteed to be bounded. Gradient oracles have been considered in the literature before \citep{dAsp08,Baes09,SchRoBa11,DeGliNe14}. The main feature of our model is that we allow stochastic noise (and bias), while most of the previous work assumes that the accuracy requirements hold with probability one, or considers adversarial noise. Our gradient oracle model applies to several gradient estimation techniques extensively used in the literature, mostly for the case when gradient estimated only based on noisy observations from the target function \citep{katkul,kushcla,spall1992multivariate,spall1997one,Dip03:AoS,bhatnagar-book,duchi2015optimal}. A particularly interesting application of our model is bandit convex optimization, where the algorithm can only query a single function value in each round, contaminated with noise \citep{PoTsy90,flaxman2005online,AbHaRa08,AgDeXi10,Ne11:TR,AgFoHsuKaRa13:SIAM,HaLe14:SOC}. As it turns out, one can construct gradient oracles we consider, reducing the analysis to our problem. Furthermore, previous practical attempts to bandit convex optimization are all centered around constructing gradient estimates that fit our model.
%((some issues with whether you can cancel the noise; we assume you cannot))A

In this paper we consider the optimization accuracy in both the online and standard optimization setting, and provide upper and lower bound on the minimax regret and, resp., optimization error for several oracle models quantifying the bias-variance tradeoff of the gradient estimate. In particular, we provide matching upper and lower bounds for optimizing smooth, convex function. We do not claim to invent methods for proving upper bounds for the stochastic case
as these methods have been developed for special cases for a long time by now (see the references above).
Our main contribution lies in abstracting away the properties of gradient estimation procedures 
to create our new oracle model, in which we are able to study not only upper rates, but also lower rates of convergence.
As a consequence, our lower bounds show that the known minimax regret of $\sqrt{T}$ \citep{shamir2012complexity}\todoa{Is this true?} cannot be achieved by the currently used gradient estimation procedures for general bounded domains where the function is only defined over the domain.

The rest of the paper is organized as follows: The problem is introduced in \cref{sec:problem}. Our upper and lower bounds on the minimax error are presented in \cref{sec:results}, with applications to bandit convex optimization in \cref{sec:ex}. Related general gradient oracle models are discussed in detail in \cref{sec:related}, while proofs are given in \cref{sec:proofs} and in the appendix.

\if0
strongly convex


Bandit convex optimization:

Online adversarial setting. Optimal rate is $\Theta(\sqrt{T})$.
No one knows general practical algorithms achieving this rate.
Strongly convex + smooth: \cite{hazan2014bandit}

Stochastic optimization setting: ??? Shamir's paper \cite{shamir2012complexity}??
Lower bounds, upper bounds for the general case?
\cite{hazan2014bandit} for upper bound.

All kind of papers about how to estimate gradients going back to maybe 70s in Russia.

One-point: \cite{flaxman2005online}

Two-point: \cite{AgDeXi10}

Lower bds: \cite{raginsky2011information} \cite{Chen88:LB-AoS}

Ellipsoid: \cite{AgFoHsuKaRa13:SIAM}



 framework
What is the problem? (New problem: Convex Optimization with Biased Gradient Oracles)
What are the results? Matching lower and upper bounds (several oracle models and relation between them; cumulative regret and optimization error (aka simple regret) and relation between them -- this is mostly known; we consider both constrained, unconstrained)
Why should we care? 
Reason 1: For bandit convex optimization we can construct these oracles and reduce to this problem.
Reason 2: Previous practical attempts for bandit convex optimization are all centered around such gradient estimates.
((some issues with whether you can cancel the noise; we assume you cannot))

Main message: Everyone was trying to get better rates with these algorithms (e.g., open question whether in the smooth case you can get better rates for these algorithms -- now we see this is not possible).
\fi
