%!TEX root =  bgo.tex
% please do not delete or change the first line (needed by Csaba's editor)
In the current era of big data, gradient based convex optimization methods are more popular than ever. Several models are considered in the literature, with using different type of gradient information, from accessing the full gradient to constructing gradient estimates only from observing samples from the target function (see, e.g., \citealp{nesterov2004introductory,HaLe14:SOC}). In this paper, we present and analyze a general framework of convex optimization with biased gradient oracle, which encompasses several models considered before.

In this model, and optimization algorithm can query the oracle repeatedly, and the oracle returns a noisy version of the gradient (or a subgradient for non-differentiable functions) in the vicinity of the query point. More specifically, the distance to the query point, as well as the bias and variance of the returned gradient estimate are guaranteed to be bounded. Gradient oracles have been considered in the literature before \citep{dAsp08,Baes09,SchRoBa11,DeGliNe14}, one key feature of our model is that it allows the algorithm to control the noise, which allows the algorithm to cancel noise in certain settings, while we also consider cases when the effect of the noise cannot be cancelled.\todoa{This difference should be explained better!!!} Our gradient oracle model applies to several gradient estimation techniques extensively used in the literature, mostly for the case when gradient estimates are constructed from noisy observations from the target function \citep{kushcla,spall1992multivariate,spall1997one,bhatnagar-book,duchi2015optimal}. A particularly interesting application of our model is bandit convex optimization, where the algorithm can only query a single function value in each round \citep{flaxman2005online,AbHaRa08,hazan2014bandit}. As it turns out, one can construct gradient oracles we consider, reducing the analysis to our problem. Furthermore, previous practical attempts to bandit convex optimization are all centered around constructing gradient estimates that fit our model.
%((some issues with whether you can cancel the noise; we assume you cannot))A

In this paper we consider the optimization accuracy in both the online and standard optimization setting, and provide upper and lower bound on the minimax regret and, resp., optimization error for several oracle models. In particular, we provide matching upper and lower bounds for optimizing smooth, convex function. In particular, our lower bounds show that the known minimiax regret of $\sqrt{T}$ cannot be achieved by the currently used gradient estimation procedures for general bounded domains where the function is only defined over the domain.

strongly convex


Bandit convex optimization:

Online adversarial setting. Optimal rate is $\Theta(\sqrt{T})$.
No one knows general practical algorithms achieving this rate.
Strongly convex + smooth: \cite{hazan2014bandit}

Stochastic optimization setting: ??? Shamir's paper \cite{shamir2012complexity}??
Lower bounds, upper bounds for the general case?
\cite{hazan2014bandit} for upper bound.

All kind of papers about how to estimate gradients going back to maybe 70s in Russia.

One-point: \cite{flaxman2005online}

Two-point: \cite{AgDeXi10}
\cite{duchi2013optimal}

Lower bds: \cite{raginsky2011information} \cite{Chen88:LB-AoS}

Ellipsoid: \cite{AgFoHsuKaRa13:SIAM}



 framework
What is the problem? (New problem: Convex Optimization with Biased Gradient Oracles)
What are the results? Matching lower and upper bounds (several oracle models and relation between them; cumulative regret and optimization error (aka simple regret) and relation between them -- this is mostly known; we consider both constrained, unconstrained)
Why should we care? 
Reason 1: For bandit convex optimization we can construct these oracles and reduce to this problem.
Reason 2: Previous practical attempts for bandit convex optimization are all centered around such gradient estimates.
((some issues with whether you can cancel the noise; we assume you cannot))

Main message: Everyone was trying to get better rates with these algorithms (e.g., open question whether in the smooth case you can get better rates for these algorithms -- now we see this is not possible).

