%!TEX root =  bgo.tex
% please do not delete or change the first line (needed by Csaba's editor)
The main application of the biased noisy gradient oracle based convex optimization of the previous section 
is to bandit convex optimization, which we briefly introduce now. Readers familiar with these problems may skip this description
and come back to it only to clarify our notation and terminology in case some confusion arises later.

In the \emph{online variant} of bandit convex optimization a learner sequentially chooses the points $X_1,\dots,X_n\in \cK$ while observing the losses $f_1(X_1),\dots,f_n(X_n)$. More specifically, in round $t$, having observed $f_1(X_1),\dots,f_{t-1}(X_{t-1})$ of the previous rounds, the learner chooses $X_t\in \cK$, after which it observed $f_t(X_t)$. The learner's goal is to minimize its expected regret $\EE{ \sum_{t=1}^n f_t(X_t) - \inf_{x\in \cK} \sum_{t=1}^n f_t(x) }$. 
This problem is also called online convex optimization with one-point feedback.
A slightly different problem is obtained if we allow the learner to choose multiple points in every round, at which points the function $f_t$ is observed. The loss is suffered at $X_t$. The points where the function is observed (``observation points'' for short) may or may not be tied to $X_t$. One possibility is that $X_t$ is one of the observation points.  
Another possibility is that $X_t$ is the average of the observation points. Yet another possibility is that there is no relationship between them. \todoc{Add refs, explain relationship between these problems.}

\todox[inline]{add the following paragraph about two-point online variant.}
For example, \cite{AgDeXi10} used an algorithm that queries at two points per round, and defined the incurred loss as the average of losses at two observation points. In our oracle, it can be stated as in round $t$, the same oracle $\gamma_t$ responds to the same inputs $(X_t, \delta_t, f_t)$ with two different pairs $(G_{t,1}, Y_{t,1})$ and $(G_{t,2}, Y_{t,2})$. The accumulated regret can be written as 
\[
R_n = \sum_{t=1}^n \dfrac{1}{2}\left( f_t(Y_{t,1})+f_t(Y_{t,2}) \right) -\inf_{x \in \cK}\sum_{t=1}^n f_t(x) \,.
\]
Recalling that $Y_{t,1}$, $Y_{t,2}$ are in the $\delta$-vicinity of $X_t$, the relationship between $f_t(X_t)$ and $\dfrac{1}{2}\left( f_t(Y_{t,1})+f_t(Y_{t,2})\right)$ is then determined by the environment (i.e. the property of $f_t$). It is straightforward to bound $| \dfrac{1}{2}\left( f_t(Y_{t,1})+f_t(Y_{t,2})\right)- f_t(X_t)|$ with $\delta$.
The common assumption for this setting is: The oracle is a stochastic mapping from $(X, \delta, f)$ to $(G, Y)$; The algorithm selects the point $X_t$ depending on $\left( X_1, G_{1,1}, G_{1,2}, \cdots, X_{t-1},G_{t-1,1}, G_{t-1,2}  \right)$. This two-point feedback can be easily extended to multi-point feedback, too.

In the \emph{optimization variant} of bandit (or ``zeroth order'') convex optimization, 
the algorithm sequentially chooses the points $X_1,\dots,X_n\in \cK$ while observing the loss function at these points in noise.
In particular, in round $t$, the algorithm chooses $X_t$ based on the earlier observations $Z_1,\dots,Z_{t-1}\in \R$ and $X_1,\dots,X_{t-1}$, after which it observes $Z_t$, where $Z_t$ is the value of $f(X_t)$ corrupted by ``noise''.
Previous research considered several possible constraints connecting $Z_t$ and $f(X_t)$.
One simple assumption is that $Z_t-f(X_t)$ is an $\cF_t = \sigma(X_{1:t},Z_{1:t-1})$-adapted martingale difference sequence (with favourable tail properties). \todoc{Some readers might be put off by martingales..}
A specific case is when $Z_t - f(X_t) = \xi_t$, where $(\xi_t)$ is an i.i.d. sequence.
A stronger assumption, which is most appropriate in stochastic programming, 
is that $Z_t = F(X_t,U_t)$, where $U_t\in \R$, $\int F(X_t,u) dF(u) = f(X_t)$ with some distribution function $F$ over the reals and the algorithm has access to an oracle that can produce independent samples from $F$ (in which case, $(U_t)$ may be an i.i.d. sequence sampled from $F$).
This assumption is stronger because the algorithm controls the ``noise''. 
In particular, the algorithm may decide to reuse the same random sample from $F$ multiple times, 
in the hope of increasing accuracy, akin to the method of common random numbers from Monte Carlo algorithms.
\todoc{mention simulation optimization as the ``field''}
Again, it is also possible to consider multi-point feedback as in the online case.

\todox[inline]{add multiple-point feedback in optimization setting}
However, what differs in optimization variant is that we do not care the incurred loss in each round, since we only need a final estimate $\hat{X}_n$, which is a deterministic function of $\left( X_1, G_{1,1}, G_{1,2}, \cdots, X_{n},G_{n,1}, G_{n,2}  \right)$ as defined earlier.

\todoc[inline]{Reduction of one-point feedback to two-point feedback}

Our oracle-based framework is relevant for bandit convex optimization problems as a major technique in bandit convex
optimization is to design gradient estimators, which are then used in conjunction with variants of gradient descent. \todoc{zillions of references.}
Next, we review the most common gradient estimation techniques and show that they are all either Type-I, or Type-II oracles.

Flaxman (actually going back to 70s in Russia): \todoc{What does it do}
Proposition:  Flaxman is $(c_1,c_2)$ Type-II oracle when $\dots$. \todoc{Expand}

One point SPSA
Proposition: One-point SPSA is blah-blah 

Two point SPSA

Proposition: Two-point SPSA is $(c_1,c_2)$ Type-I oracle when $\cF$ contains only $3$-times continuously differentiable functions where  $c_1 = \cdot$, $c_2 = \dots$. \todoc{Make this precise, add proof.}

\todoc[inline]{Different regularity conditions on $\cF$! Strong convexity, smoothness, etc.}

