%!TEX root =  bgo.tex
% please do not delete or change the first line (needed by Csaba's editor)
The main application of the biased noisy gradient oracle based convex optimization of the previous section 
is to bandit convex optimization, which we briefly introduce now. Readers familiar with these problems may skip this description
and come back to it only to clarify our notation and terminology in case some confusion arises later.

In the \emph{online variant} of bandit convex optimization a learner sequentially chooses the points $X_1,\dots,X_n\in \cK$ while observing the losses $f_1(X_1),\dots,f_n(X_n)$. More specifically, in round $t$, having observed $f_1(X_1),\dots,f_{t-1}(X_{t-1})$ of the previous rounds, the learner chooses $X_t\in \cK$, after which it observed $f_t(X_t)$. The learner's goal is to minimize its expected regret $\EE{ \sum_{t=1}^n f_t(X_t) - \inf_{x\in \cK} \sum_{t=1}^n f_t(x) }$. 
This problem is also called online convex optimization with one-point feedback.
A slightly different problem is obtained if we allow the learner to choose multiple points in every round, at which points the function $f_t$ is observed. The loss is suffered at $X_t$. The points where the function is observed (``observation points'' for short) may or may not be tied to $X_t$. One possibility is that $X_t$ is one of the observation points.  
Another possibility is that $X_t$ is the average of the observation points. Yet another possibility is that there is no relationship between them. \todoc{Add refs, explain relationship between these problems.}

\todox[inline]{add the following paragraph about two-point online variant.}
\todoc{We need mathematical statements: Under such and such conditions, $d$-point feedback is equivalent to $2$-point feedback, which is equivalent to having a $(c_1,c_2)$ Type-I oracle with $c_1,c_2$ such and such.}
For example, \cite{AgDeXi10} used an algorithm that queries at two points per round, and defined the incurred loss as the average of losses at the two observation points. In our oracle, it can be stated as in round $t$, the same oracle $\gamma_t$ responds to the same inputs $(X_t, \delta_t, f_t)$ with two different pairs $(G_{t,1}, Y_{t,1})$ and $(G_{t,2}, Y_{t,2})$. The accumulated regret can be written as 
\[
R_n = \sum_{t=1}^n \dfrac{1}{2}\left( f_t(Y_{t,1})+f_t(Y_{t,2}) \right) -\inf_{x \in \cK}\sum_{t=1}^n f_t(x) \,.
\]
Recalling that $Y_{t,1}$, $Y_{t,2}$ are in the $\delta$-vicinity of $X_t$, the relationship between $f_t(X_t)$ and $\dfrac{1}{2}\left( f_t(Y_{t,1})+f_t(Y_{t,2})\right)$ is then determined by the environment (i.e. the property of $f_t$). It is straightforward to bound $| \dfrac{1}{2}\left( f_t(Y_{t,1})+f_t(Y_{t,2})\right)- f_t(X_t)|$ as a function of $\delta$. \todoc{How? When $f_t$ is Lipschitz, smooth, etc? So you mean, when $f_t$ is a smooth function?}
The common assumption for this setting is: The oracle is a stochastic mapping from $(X, \delta, f)$ to $(G, Y)$; The algorithm selects the point $X_t$ depending on $\left( X_1, G_{1,1}, G_{1,2}, \cdots, X_{t-1},G_{t-1,1}, G_{t-1,2}  \right)$. This two-point feedback can be easily extended to multi-point feedback, too.

In the \emph{optimization variant} of bandit (or ``zeroth order'') convex optimization, 
the algorithm sequentially chooses the points $X_1,\dots,X_n\in \cK$ while observing the loss function at these points in noise.
In particular, in round $t$, the algorithm chooses $X_t$ based on the earlier observations $Z_1,\dots,Z_{t-1}\in \R$ and $X_1,\dots,X_{t-1}$, after which it observes $Z_t$, where $Z_t$ is the value of $f(X_t)$ corrupted by ``noise''.
Previous research considered several possible constraints connecting $Z_t$ and $f(X_t)$.
One simple assumption is that $Z_t-f(X_t)$ is an $\cF_t = \sigma(X_{1:t},Z_{1:t-1})$-adapted martingale difference sequence (with favourable tail properties). \todoc{Some readers might be put off by martingales..}
A specific case is when $Z_t - f(X_t) = \xi_t$, where $(\xi_t)$ is an i.i.d. sequence.
A stronger assumption, which is most appropriate in stochastic programming, 
is that $Z_t = F(X_t,U_t)$, where $U_t\in \R$, $\int F(X_t,u) dF(u) = f(X_t)$ with some distribution function $F$ over the reals and the algorithm has access to an oracle that can produce independent samples from $F$ (in which case, $(U_t)$ may be an i.i.d. sequence sampled from $F$).
This assumption is stronger because the algorithm controls the ``noise''. 
In particular, the algorithm may decide to reuse the same random sample from $F$ multiple times, 
in the hope of increasing accuracy, akin to the method of common random numbers from Monte Carlo algorithms.
\todoc{mention simulation optimization as the ``field''}
Again, it is also possible to consider multi-point feedback as in the online case.

\todox[inline]{add multiple-point feedback in optimization setting}
However, what differs in optimization variant is that we do not care the incurred loss in each round, since we only need a final estimate $\hat{X}_n$, which is a deterministic function of $\left( X_1, G_{1,1}, G_{1,2}, \cdots, X_{n},G_{n,1}, G_{n,2}  \right)$ as defined earlier.

\todoc[inline]{Reduction of one-point feedback to two-point feedback}

Our oracle-based framework is relevant for bandit convex optimization problems as a major technique in bandit convex
optimization is to design gradient estimators, which are then used in conjunction with variants of gradient descent. \todoc{zillions of references.}
Next, we review the most common gradient estimation techniques and show that they are all either Type-I, or Type-II oracles.

Flaxman (actually going back to 70s in Russia): \todoc{What does it do}
Proposition:  Flaxman is $(c_1,c_2)$ Type-II oracle when $\dots$. \todoc{Expand}
\todox[inline]{Flaxman's estimator}

A popular idea for estimating gradient using one-point feedback is the smoothed function approach, which was originally proposed in \citep{katkul}. The idea is to convolve the gradient of the objective function with a suitable density function and then, via an integration by parts arguments show that the resulting integral is an estimate of the gradient of the smoothed objective function. 
% This approach has been adopted in a stochastic convex optimization setup in \cite{duchi2015optimal}. 
\cite{flaxman2005online} follow this approach in the context of bandit convex optimization.
Formally,  
% a $(c_1,c_2)$ Type-II oracle when $\cF$ is a general class of functions (this does not even require differentiability).
given any $f \in \cF$, $x \in \cK$, and $\delta >0$, the oracle returns\footnote{See also \cite[pp.~58-60]{kushcla} for an old reference that proposed a gradient estimate similar to \eqref{eq:flaxman}.}   
\begin{align}
 Y = x+\delta u \in \cK', \quad
 G = \dfrac{d}{\delta}f(x+\delta u)u \in \R^d, \label{eq:flaxman}
\end{align}
where $u\in \R^d$ is a random unit vector, so the first condition of \cref{def:oracle2} immediately follows. 
The variance of $G$ is bounded by $d^2C^2 \delta^{-2}$ for some constant $C = \sup_{y\in \cK'}f(y)$. 
\begin{proposition}
Let $\tilde{f}(x) = \EE{f(x+\delta v)}$ denote the smoothed version of $f$. Then, we have
$\EE{G} = \nabla \tilde{f}(x)$.
\end{proposition}
\begin{proof}
 See Lemma 1 in \citep{flaxman2005online}.
\end{proof}
 As to the bias condition, it was proved that $\EE{G} = \nabla \tilde{f}(x)$, where $\tilde{f}$ is a smoothed version of $f$, i.e.,
$\tilde{f}(x) = \EE{f(x+\delta v)}$,
$v$ is a random vector in a unit ball. There are different ways to bound the bias depending on the property of $f$.
If $f$ is $L_{lip}$-Lipschitz over $\cK'$, then we have
\begin{align*}
\MoveEqLeft
\norm{\tilde{f}(x)-f(x)}_\infty \\
=&\norm{\EE{f(x+\delta v)-f(x)}}_\infty
\le L_{lip} \delta \,.
\end{align*}
If $f$ is convex, and $L_{smo}$-smooth, 
\begin{align*}
\MoveEqLeft
\norm{\tilde{f}(x)-f(x)}_\infty \\
\le& \norm{\EE{\ip{\nabla f(x), \delta v}+\dfrac{L_{smo}}{2}\delta^2\norm{v}^2}}_\infty\\
\le &\dfrac{L_{smo}}{2}\delta^2 \,.
\end{align*}
Therefore, the estimator \eqref{eq:flaxman} can always fit the oracle setting by choosing $c_1(\delta) = C_1 \delta$ (or $C_1\delta^2$), $c_2(\delta) = C_2 \delta^{-2}$, for some constant $C_1$, $C_2$.

\begin{remark}
 Instead of picking $u$ randomly on the surface of a unit sphere, one can employ an random variable $u$ that satisfies $E[u u\tr] = I_d$, where $I_d$ is the $d$-dimensional identity matrix. A popular choice for $u$ that satisfies the aforementioned constraint is the $d$-dimensional standard Gaussian - a choice that has been explored in the context of zeroth order optimization in \citep{duchi2015optimal}. See \citep{bhatnagar-book} for an overview of gradient and Hessian estimation techniques using random perturbations.   
\end{remark}

\todox[inline]{mention Dikin}
It may be noticed that the set $\cK'$ can be different from $\cK$. This is not a issue when the oracle can be queried outside $\cK$. However, if it is not the case, the algorithm can project $X$ to a shrinked set $(1-\delta)\cK$ (\cite{flaxman2005online}), or use Dikin ellipsoid (\cite{AbHaRa08}).

An alternative approach, popularly known as SPSA \citep{spall1997one}, employs independent Rademacher random variables $\Delta_i, i=1,\ldots,d$ to estimate the gradient as follows:
% 
% One point SPSA
% Proposition: One-point SPSA is blah-blah 
% The one-point SPSA given by \cite{spall1997one} is a $(c_1,c_2)$ Type-I oracle when $\cF$ contains only $3$-times continuously differentiable functions where  $c_1 = C_1 \delta^2$, $c_2 = C_2 \delta^{-2}$ for some constant $C_1$, $C_2$.
For any input triple $(x, \delta, f)$, the oracle responds with
\begin{align}
Y = x+\delta \Delta \,, \quad
G = \dfrac{f(Y)+\epsilon}{\delta}\begin{pmatrix}\Delta_{\cdot1}^{-1}\\\Delta_{\cdot2}^{-1}\\ \vdots\\ \Delta_{\cdot
 d}^{-1}\end{pmatrix} \,,
 \label{eq:onespsa}
\end{align}
where $\epsilon$ is zero-mean measurement noise. More general distributions could be used for the perturbations $\Delta$, as long as they zero mean and satisfy bounded second and inverse second moments.
\todox{For one-point SPSA, $\Delta$ has to be symmetric around origin to eliminate the $f(x)$, $f'(x)$ terms}
% , $\Delta=\left(\Delta_{\cdot1}, \Delta_{\cdot2}, \cdots, \Delta_{\cdot
%  d}  \right)^\top$ is a vector of independent random variables. Each $\Delta_{\cdot i}$ is symmetrically distributed around $0$. $\EE{\Delta_{\cdot i}^{-1}}$ exists and is bounded.  The second and third moment of $\Delta$ are also bounded.

% 
% Proposition: Two-point SPSA is $(c_1,c_2)$ Type-I oracle when $\cF$ contains only $3$-times continuously differentiable functions where  $c_1 = \cdot$, $c_2 = \dots$. \todoc{Make this precise, add proof.}
% \todox[inline]{two-point SPSA}
% The two-point SPSA (\cite{spall1992multivariate}) is quite similar. However, the oracle 
Using two-point feedback, the original SPSA algorithm \citep{spall1992multivariate} based oracle    
will respond to $(x,\delta,f)$ with
\begin{align}
Y^+ &= x+\delta \Delta \,,\quad
Y^- = x-\delta \Delta \,, \\
G =& \dfrac{\left(f(Y^+)+\epsilon^+\right) - \left(f(Y^-)+\epsilon^-\right)}{2\delta}\begin{pmatrix}\Delta_{\cdot1}^{-1}\\\Delta_{\cdot2}^{-1}\\ \vdots\\ \Delta_{\cdot
 d}^{-1}\end{pmatrix} \,.
 \label{eq:twospsa}
\end{align}

\begin{proposition}
\label{prop:grad-spsa}
 Assume $f$ is $3$-times continuously differentiable. Then, for $G$ governed by either \eqref{eq:onespsa} or \eqref{eq:twospsa}, we have
 \begin{align*}
&\EE{G_{\cdot i}}= [f'(x)]_i +O(\delta^2) \,, \quad \text{ for } i=1,\ldots,d.
\end{align*}
\end{proposition}
\begin{proof}
 See Appendix \ref{sec:appendix-grad}.
\end{proof}

From the foregoing, it is easy to see that, for $3$-times continuously differentiable functions, one-point and two-point SPSA are $(c_1,c_2)$ Type-I oracles with $c_1 = C_1 \delta^2$, $c_2 = C_2 \delta^{-2}$ for some constant $C_1$, $C_2$.

% Under this situation, using Taylor expansion again, the $f(x)$ and $f''(x)$ terms in \eqref{eq:spsaTaylorExp} can be canceled. As a result, we only need $\Delta_{\cdot i}$ to be zero-mean instead of symmetry.


\todoc[inline]{Different regularity conditions on $\cF$! Strong convexity, smoothness, etc.}