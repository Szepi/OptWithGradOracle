%!TEX root =  bgo.tex
% please do not delete or change the first line (needed by Csaba's editor)

Bandit convex optimization:

Online adversarial setting. Optimal rate is $\Theta(\sqrt{T})$.
No one knows general practical algorithms achieving this rate.
Strongly convex + smooth: Hazan + Levy (NIPS last year).

Stochastic optimization setting: ??? Shamir's paper??
Lower bounds, upper bounds for the general case?
Hazan + Levy for upper bound.

All kind of papers about how to estimate gradients going back to maybe 70s in Russia.
