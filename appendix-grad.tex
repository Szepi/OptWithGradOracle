%!TEX root =  bgo.tex
% please do not delete or change the first line (needed by Csaba's editor)
\subsubsection*{Proof of Proposition \ref{prop:grad-spsa} for $f \in \C^3$}
\begin{proof}
We use the proof technique of \cite{spall1992multivariate} (in particular, Lemma 1 there) in order to prove the main claim here.
By our assumptions on $\xi^{\pm}$ and $V$,  we have
\begin{align*}
&\E\left[  V\left(\dfrac{\xi_n^+ - \xi_n^-}{2\delta}\right) \right]= 0 
\end{align*}
implying that
\begin{align*}
\E[G] =  \E\left[V\,  \dfrac{f(X^+)  -f(X^-)}{2\delta} \right]\,.
\end{align*}

By Taylor's theorem, using that $f\in C^3$, we obtain, a.s., \todoc{I am using the integral form, because otherwise you would need to argue that the point picked on the line segment between $x$ and $x\pm \delta U$ is measurable.
For the notation etc see \url{http://www.gold-saucer.org/math/taylor/taylor.pdf}
}
\begin{align*}
f(x \pm \delta U) =
 f(x) 
 \pm\delta\,  U\tr\,\nabla f(x)   
  + \frac{\delta^2}{2}\, U\tr \nabla^2 f(x) U 
  \pm  \frac{\delta^3}{2} \, R^{\pm}(x,\delta,U) \,(U, U, U),
\end{align*}
where
$R^{\pm}(x,\delta,U)= \int_0^1  \nabla^3 f(  x \pm s \, \delta U ) (1-s)^2 ds $ and $\nabla^3 f(\cdot)$ is considered as a rank-3 tensor.
Letting $B_3 = \sup_{x\in D} \norm{ \nabla^3 f(x) }$,%
\footnote{Here, $\norm{\cdot}$ is the implied norm: For a rank-3 tensor $T$, $\norm{T} = \sup_{x,y,z\ne 0}
\frac{|T (x,y,z)|}{\norm{x}\norm{y}\norm{z}}$.
}
we have $\norm{ R^{\pm}(x,\delta,U)} \le B_3/3$ a.s.
Now,
\begin{align}
\begin{split}
\MoveEqLeft       V\, \dfrac{f(X^+)-f(X^-)}{2\delta}
  = V\, \dfrac{f(x+\delta U) - f(x-\delta U)}{2\delta} \\
&= VU^{\tr}
\, \nabla f(x)   +   \frac{\delta^2}{4}  V \,(R^{+}(x,\delta,U)+R^{-}(x,\delta,U))(U \otimes U \otimes U)\,. 
\end{split}
\label{eq:l1}
\end{align}
and therefore, 
by taking the expectations of both sides, 
using that $\EE{V U\tr} = I$ and then using $|R^{\pm}(x,\delta,U) (U \otimes U \otimes U)| \le 
\norm{R^{\pm}(x,\delta,U)} \norm{U}^3$, 
we get that
\begin{align*}
\norm{ \EE{ G } - \nabla f(x) }_* 
\le \frac{B_3 \EE{ \norm{V}_* \norm{U}^3 }}{6}\,\, \delta^2 \,.
\end{align*}

Let us now bound the variance of $G$:
Using the identity $\E\left\|X -  E[X]\right\|^2 \le 4 \E \left\|X\right\|^2$, which holds for any random variable $X$,%
\footnote{When $\norm{\cdot}$ is defined from an inner product, 
$\E\left\|X -  E[X]\right\|^2 = \EE{\norm{X}^2} - \norm{\EE{X}}^2 \le \EE{\norm{X}^2}$ also holds, shaving off a factor of four from the inequality below.}
we bound $\E\left\| G - \E G\right\|^2$ as follows:
\begin{align}
\MoveEqLeft \E\left\| G - \E G\right\|^2 
 \le 4 \E \left\|G\right\|^2 \nonumber \\
& =  4\E\left( \left\| V \right\|_*^2 \left(\left(\dfrac{\xi^+ - \xi^-}{2\delta}\right)^2  + 2 \left(\dfrac{\xi^+ - \xi^-}{2\delta}\right) \left(\dfrac{f(X^+) - f(X^-)}{2\delta}\right) 
+ \left( \dfrac{f(X^+) - f(X^-)}{2\delta} \right)^2 \right)\right) \nonumber \\
&=  4\E\left( \left\| V \right\|_*^2 \left(\dfrac{\xi^+ - \xi^-}{2\delta}\right)^2\right)   
+ 4 \E \left(\left\| V \right\|_*^2 \right)\left( \dfrac{f(X^+) - f(X^-)}{2\delta} \right)^2  \label{eq:h3} \\
& \le  \frac{C_2}{\delta^2}\,, \nonumber \label{eq:h4}
\end{align}
where $C_2 = 4 \EE{\norm{V}_*^2}\left( \sigma_\xi^2+\fspan(f)\right)$ 
and $\fspan(f) = \sup_{x\in \D} f(x) - \inf_{x\in \D} f(x)$.
The equality in \eqref{eq:h3} follows from $\EE{ \xi^+ \,|\, V } = \EE{ \xi^- \,|\, V } = 0$.
\end{proof}

\subsubsection*{Proof of Proposition \ref{prop:grad-spsa} for convex and smooth $f$}
\begin{proof}
\todop{Got to read this proof carefully to see if all the constants are right and if the dual norm is applied right.}
Since $f$ is convex with a  $L$-Lipschitz gradient, we have the following for any $\delta>0$:
\begin{align*}
\frac{\<\nabla f(x), \delta u\>}{2\delta} \le \frac{f(x + \delta u) -  f(x)}{2\delta} \le& \frac{\<\nabla f(x), \delta u\> + (L / 2) \norm{\delta u}^2}{2\delta}.
\end{align*}
Using similar inequalities for $f(x-\delta u)$, we obtain
\begin{align*}
\<\nabla f(x), u\> - \frac{L \delta \norm{ u}^2}{2} \le \frac{f(x + \delta u) -  f(x-\delta u)}{2\delta} \le& \<\nabla f(x), u\> + \frac{L \delta \norm{ u}^2}{2}.
\end{align*}
Letting 
$\phi(x,\delta,u):=\frac1{\delta}\left(\frac{f(x + \delta u) -  f(x-\delta u)}{2\delta} - \<\nabla f(x),  u\>\right)$, we have
\begin{align*}
\left|\phi(x,\delta,u) \right| \le&  \dfrac{L}{2} \norm{u}^2\,.
% \frac{f(x - \delta u) -  f(x)}{\delta} \le& -\frac{\<\nabla f(x), \delta u\> + (L / 2) \norm{\delta u}^2}{\delta}
\end{align*}

Recall, from the proof of Proposition \ref{prop:grad-spsa} for $f\in \C^3$, that 
%for the gradient estimate $G:= V\, \left( \frac{f(X^+) + \xi^+  - (f(X^-) + \xi^-)}{2\delta}\right)$, 
we have
$\E[G] =  \E\left[V\,  \left(\tfrac{f(X^+)  -f(X^-)}{2\delta}\right) \right]$. Besides, given $\EE{V U^\top}=I$,  we get
\begin{align*}
 \norm{\E[G] - \nabla f(x)} 
 = \scnorm{\E\left[V\,  \left(\frac{f(x+\delta U)  -f(x-\delta U)}{2\delta}\right)-V U^\top\nabla f(x) \right]}
 \le \delta \norm{\E[ V \phi(x,\delta, U)]}
 \le \frac{\delta L}{2} \E[ \dnorm{V} \norm{U}^2],
\end{align*}
and the claim for the bias follows by setting $c_1(\delta)= \frac{\delta L}{2} \E[ \dnorm{V} \norm{U}^2]$.

In the case of controlled noise, i.e., $\xi^+ = \xi^-$, 
\begin{align*}
 \E \norm{G}^2 
& = \mathbb{E}\norm{V\left(\delta \phi(x,\delta, U)+ U^\top\nabla f(x) \right)}^2
 \le  \E\left[ \left( \dnorm{ V U \tr \nabla f(x)} + \frac{\delta L}{2} \dnorm{V} \norm{U}^2 \right)^2\right]\\
& \le  2 \E\left[  \dnorm{ V U \tr \nabla f(x)}^2\right]  + \frac{\delta^2 L^2}{2}\E\left[ \dnorm{V}^2 \norm{U}^4 \right],
\end{align*}
and the claim for the variance follows by setting $c_2(\delta) = C_2$, 
where $C_2 =  2 L^2  + \frac{ L^2}{2}\E\left[ \dnorm{V}^2 \norm{U}^4 \right]$.

For the case of uncontrolled noise, the claim for the variance, i.e., $c_2(\delta) = C_2/\delta^2$ follows in the same manner as that in the proof of Proposition \ref{prop:grad-spsa}.
\end{proof}


\subsubsection*{One-point estimates}
\begin{proposition}
\label{prop:grad-onepoint}
For one-point feedback oracle, i.e.,
\begin{align*}
G = \dfrac{Z}{\delta}V, \quad Z=f(x+\delta U)+\xi\,,
\end{align*}
in addition to the conditions in Proposition \ref{prop:grad-spsa}, we further assume $\EE{V}=0$, and for $f \in \C^3$, more specifically, $V$ is a deterministic odd function of $U$ and $U$ symmetrically distributed. Then, $\gamma$ is a type-I oracle with $c_1(\delta)$ and $c_2(\delta)$ same as the uncontrolled noise case in \cref{tab:oracles}.
\todoc{Add the convex+smooth case}
\end{proposition}


\if0
\begin{proposition}
\label{prop:grad-1spsa}
Given any $f$ that is three times continuously differentiable with bounded third derivative. 
For any $x \in \cK$, and $\delta >0$, let oracle $\gamma$ return 
\begin{align}
% Y = x+\delta U \,, \quad
G =  V \left(\dfrac{f(x+\delta U) + \xi}{\delta}\right),
 \label{eq:onesp}
\end{align}
where $V, U$ are random variables that satisfy $\E[V U\tr] = I_d$, $U_i, i=1,\ldots,d$ are i.i.d., $\E[ V U^2] = 0$, $\E[V_i]=0$, $|U_i|$ and $\E|V_i|$ have finite upper bounds. 
Then, we have that $\gamma$ is a type-I oracle with $c_1(\delta) = C_1 \delta^2$ and $c_2(\delta) = C_2/\delta^2$.
\end{proposition}
\fi
\begin{proof}
\todoc[inline]{This proof must be updated to follow the proof of Prop 1. Don't write $\le O(\cdot)$,for example.}
As in the case of two-point feedback, we can ignore the noise element in $G$, i.e.,
\begin{align*}
&\E\left[  V \vert \xi \right]= 0 \quad \Rightarrow \quad
\E[G] =  \E\left[ V \left(\dfrac{f(x+\delta U) }{\delta}\right)\right],
\end{align*}

% By Taylor's series expansions, we obtain, a.s.,
% \begin{align*}
% f(x + \delta U) = f(x) \pm \delta U\tr \nabla f(x) + \frac{\delta^2}{2} U\tr \nabla^2 f(x) U +  \frac{\delta^3}{6} \nabla^3 f(\tilde x^{+})(U \otimes U \otimes U),
% \end{align*}
% where $\otimes$ and $\tilde x^+$ are as in the proof of Proposition \ref{prop:grad-spsa}.
Using suitable Taylor's series expansions, we have %the following for any $i=1,\ldots,d$:
\begin{align}
&\E\left[V\left(\dfrac{f(x+\delta U)}{\delta}\right) \right] \nonumber\\
= & \E\left[V \dfrac{f(x)}{\delta} \right] + \E\left[V U\tr \left.\nabla f(x)\right| \F_n\right]  +   \E\left[\frac{\delta}{2}  \nabla^2 f(\tilde  x^+)(V \otimes U \otimes U)\right] + \O\left( \delta^2\right). \label{eq:l1}\\
\le & \nabla f(x) + \O\left( \delta^2\right).\label{eq:l2}
\end{align}
The last inequality follows from the facts that $E[V U\tr] = I$, and for any $i=1,\ldots,d$, $E[V_i U_j^2] = 0$, $|U_i|$ and $\E|V_i|$ have finite upper bounds.
\end{proof}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\subsubsection*{One point estimates with smoothing}
\todoc[inline]{Someone should finish this. And ideally add a remark if not a proposition that this is not the only way, e.g., Gaussian smoothing and friends.}
\begin{proposition}
\label{prop:flaxman}
In the one-point feedback, let
\begin{align*}
V = n_W(U)\dfrac{\lvert \partial W\rvert}{\lvert W \rvert}\,,
\end{align*}
where $W$ is a convex body with surface $\partial W$, $U \in \partial W$ is uniformly distributed. $n_W(U)$ denotes the normal vector of $\partial W$ at $U$, and $\lvert \cdot \rvert$ denotes the volume. Then, $\gamma$ is a type-II oracle with $c_2(\delta) = C_2/\delta^2$.
\todox{$c_1$ depends on property of $f$.}
\end{proposition}
\begin{proof}
this will go elsewhere.
\end{proof}


% 
% \paragraph{One-point SPSA:}
% 
%  Since $f$ is $3$-times continuously differentiable, using Taylor's expansion, we get for the the $i^{th}$ component of $G$,
% \begin{align*}
% &\EE{G_{\cdot i}}\\
% =&\EE{\dfrac{1}{\delta \Delta_{\cdot i}} \left( f(x+\delta \Delta)+\epsilon \right) }\\
% =& \EE{\dfrac{1}{\delta \Delta_{\cdot i}} \left( f(x)+\delta f'(x)^\top \Delta+\dfrac{1}{2}\delta^2 \Delta^\top f''(x)\Delta \right) } \numberthis \label{eq:spsaTaylorExp} \\
% &+\EE{\dfrac{1}{\delta \Delta_{\cdot i}} \left(O(\delta^3 \Delta\otimes\Delta\otimes\Delta) +\epsilon \right) }\\
% =& [f'(x)]_i +O(\delta^2) \,,
% \end{align*}
% where $[f'(x)]_i$ denotes the $i^{th}$ component of $f'(x)$. The last equality comes from the properties of symmetry, and bounded moment for $\Delta$.
% Hence, $G$ is a estimate of $f'(x)$ with bias $O(\delta^2)$.
% 
% \paragraph{Two-point SPSA:}
% 
% Under this situation, using Taylor expansion again, the $f(x)$ and $f''(x)$ terms in \eqref{eq:spsaTaylorExp} can be canceled and one can conclude that $G$ is only an order $O(\delta^2)$ term away from $f'(x)$. Note that the second-order term in one-point SPSA is zero-mean, while in the two-point SPSA it is zero. 
% As a result, we only need $\Delta_{\cdot i}$ to be zero-mean instead of symmetry.
