\documentclass[11pt,letterpaper,english]{article}

\input{commands}
\newcommand{\Borel}{\fB}
\newcommand{\Cb}{\cC_b}
\begin{document}
Let $\cX$ be a Banach space over the reals $\R$, 
$\cX^*$ its topological dual (i.e., the set of continuous linear, $\R$-valued functionals on $\cX$). 
We shall assume that $\cX^*$ is separable. \todoc{needed?}
We will denote the value $\phi(x)$ of a functional $\phi$ from $\cX^*$ applied to a vector $x\in \cX$ by $\ip{\phi,x}$.
We will treat $\cX$ as a measurable space with the Borel $\sigma$-algebra $\Borel(\cX)$ on it. 

Let $\cY$ be a Banach space.
An $\cY$-valued vector measure $\nu$ is called finite if for any $A\in \Borel(\cX)$, $\norm{\nu(A)}<\infty$.
The convolution of a measurable function  $f: \cX \to \R$  and a measure $\mu$ on $\cX$ at $x\in \cX$ is defined as
\todoc{Changed to $y-x$..}
\begin{align*}
\left( f*\mu \right) (x) := \int f(y-x)\mu (d y)
 %= \int f(y)\mu(x+dy)
 = \int f(y)\mu_x(dy)\,,
\end{align*}
where $\mu_x$ is defined by $\mu_x(A) = \mu(x+A)$ ($A\in \Borel(\cX)$). 
Let $\Cb(\cX)$ denote the set of continuous, bounded, real-valued functions defined on $\cX$.
%Now we can see $\left\lbrace \mu_x: x\in \cX \right\rbrace$ is a family of measures with the parameter $x$. 
\begin{definition}
We say that $\mu_x$ is \emph{weakly differentiable} 
at $x_0\in \cX$ with weak derivative $\mu'_{(x_0)}$, if 
 $\mu'_{(x_0)}: \Borel(\cX)\to \cX^*$ is a finite measure such that for any $f \in \Cb(\cX)$,
\begin{align*}
\int f(y)\mu_{x_0+\xi}(dy) - \int f(y)\mu_{x_0}(dy)
-\int f(y)\ip{\mu'_{(x_0)}(dy), \xi} = o(\norm{\xi}) \,\text{ as } \norm{\xi}\to 0\,.
\end{align*}
\end{definition}
\todoc{How is integration defined? Why is $f$ $\mu_{(x_0)}'$ integrable?
If we used instead $\int f(y) \ip{ \mu'_{(x_0)}(dy),\xi}$, the first question would not arise:
$\ip{\mu'_{(x_0)}(\cdot),\xi}$ is an ordinary signed measure.
}
The definition immediately gives the following:
\begin{proposition}
The measure $\mu'_{(x)}$, when exists, is uniquely defined.
Further, for any $x,x'\in \cX$,  $\mu'_{(x)}(\cdot) = \mu'_{(x')}(x-x'+\cdot)$. So, we will simply denote $\mu'_{(x)}$ as $\mu'_{x}$ in the following.
\end{proposition}

Recall that the function $f: \cX \to \R$ is differentiable at $x_0\in \cX$ (in the Fr\'echet sense) if 
for some $g\in X^*$,
\begin{align*}
f(x_0+\xi) - f(x_0) - \ip{g,\xi} = o(\norm{\xi}) \text{ as } \norm{\xi} \to 0\,.
\end{align*}
Then, $g$ is called the derivative of $f$ at $x_0$ and is denoted by $\frac{d}{dx}f(x_0)$.
\begin{proposition}
\label{prop:diffconvolution}
Consider the following statements:
\begin{enumerate}
\item \label{prop:diffc:1}
	 For any $f \in \Cb(\cX)$, $f*\mu$ is differentiable at all points $x_0\in \cX$; 
\item \label{prop:diffc:2}
	 For any $f \in \Cb(\cX)$, $f*\mu$ is differentiable at some point $x_0\in \cX$; 
\item \label{prop:diffc:3}
	 $\mu$ is weakly differentiable. 
\end{enumerate}
\eqref{prop:diffc:3} implies \eqref{prop:diffc:1}. \eqref{prop:diffc:1} implies \eqref{prop:diffc:2}. When $f$ is also compactly supported, \eqref{prop:diffc:2} implies \eqref{prop:diffc:3}.
Moreover, when  for some $f\in \Cb(\cX)$, $f*\mu$ is differentiable at $x_0\in \cX$,
$\frac{d}{dx} (f*\mu) (x_0) = \int f(y)\mu'_{x_0}(dy)$.
\end{proposition}
\begin{proof}
 \eqref{prop:diffc:1} $\Rightarrow$ \eqref{prop:diffc:2} is obvious.
 
 \eqref{prop:diffc:2} $\Rightarrow$ \eqref{prop:diffc:3}:
 Fix $x_0\in \cX$ and pick any $f\in\Cb(\cX)$.
Denote $\hat{f}(x) := (f*\mu)(x)$. 
Since $\hat{f}$ is differentiable at $x_0$, there exists $g_f \in \cX^*$ such that
\begin{align}
\label{eq:diffhatf}
\hat{f}(x_0+\xi) - \hat{f}(x_0) 
= \int f(y)\mu_{x_0+\xi}(dy) - \int f(y)\mu_{x_0}(dy)
= \ip{g_f, \xi}+o(\norm{\xi}) \,.
\end{align}
Then, $\Lambda:\Cb(\cX) \to \cX^*$, defined by $\Lambda(f)= g_f$ is a bounded, linear operator (here, $\Cb(\cX)$ is taken with the $\norm{\cdot}_\infty$ topology). By the Riesz representation theorem,  \todoc{Which one?} 
$\Lambda(f) = \int f(y) \lambda(y)$ for some $\cX^*$-valued measure $\lambda$ on $(\cX,\Borel(\cX))$.
\todoc{Things are a little fishy here.}
\todoc[inline]{
Choose some $\cX^*$-valued measure $\lambda$ such that 
$g_f = \int f(y)\lambda(dy)$, 
then plug this into \eqref{eq:diffhatf}.}
Recalling the definition of weak differentiability, we can see that $\lambda$ is the weak derivative of $\mu$. 

 \eqref{prop:diffc:3} $\Rightarrow$ \eqref{prop:diffc:1}:
Let $g_f=\int f(y)\mu'_{x_0}(dy)$. It is obvious that \eqref{eq:diffhatf} will also hold. 
Therefore, $f*\mu$ is differentiable and its derivative  at $x_0$ is $\int f(y)\mu'_{x_0}(dy)$.
\end{proof}
\todoc[inline]{I looked up to this point.}

Now we want to give a probability based representation of $\dfrac{d}{dx} (f*\mu) (x_0)$.

By \cref{prop:diffconvolution}, we have for any $x\in \cX$,
\begin{align*}
\dfrac{d}{dx} (f*\mu) (x) = \int f(y)\mu'_{x}(dy)
= \int f(y-x)\mu'(dy) \,,
\end{align*}
where the second equality results from the definition $\mu'_{x}(A)=\mu'(x+A)$. 
Since $\mu':\cX\to \cX^*$ is a finite measure, it has bounded total variation. The total variation of $\mu'$ is defined by
\begin{align*}
\vert \mu' \vert (A) = \sup_{\pi(A)} \sum_{E\in \pi(A)} \norm{\mu'(E)}_*, \quad \forall A \in \Borel(\cX) \,,
\end{align*}
where the supremum is over all finite partition $\pi(A)$ of $A$ into disjoint members of $\Borel(\cX)$.
Then we can define 
\todoc{We should be using the total variation measure.}
\begin{align*}
\forall A \in \Borel(\cX), \quad
\nu(A) = \dfrac{\vert \mu' \vert (A)}{\vert \mu' \vert (\cX)}\,,
\end{align*}
which is a probability measure. Hence 
$\dfrac{d}{dx} (f*\mu) (x) =  \int f(y-x) \dfrac{d\mu'}{d\nu}(y) \nu(dy)$, where $\dfrac{d\mu'}{d\nu}$ is the Radon-Nikodym derivative of $\mu'$ w.r.t $\nu$.

In what follows we look at some special cases when the measure-derivatives can be calculated.
\section{$\mu$ has a density}
Assume now that $\mu$ is a probability measure with the probability density function $p(\cdot)$, i.e., $\mu(dx) = p(x)dx$. If $p(x)$ is differentiable, then
$\nu(dy) = \dfrac{\norm{p'(y)}_*}{\int \norm{p'(x)}_*dx}dy$.
So we have
\begin{align*}
\dfrac{d}{dx} (f*\mu) (x) =  \int f(y-x) q(y) \nu (dy)\,,
\end{align*}
where $q(y) = \dfrac{p'(y)}{\norm{p'(y)}_*}\int \norm{p'(x)}_*dx$.

In particular, when $\mu$ is the Gaussian distribution $N(0, \sigma^2 I)$, where $I$ is the $d$-dimensional identity matrix.  Its measure derivative is
$\mu'(dy) = -\dfrac{1}{\sigma^2}y\mu(dy)$.
%Let $\norm{\cdot}$ be the Euclidean norm, we have that $q(y) \nu (dy) = -\dfrac{1}{\sigma^2}y\mu(dy)$. 
Select the random variable $U$ from the distribution $\mu$, 
after writing the integral into expectation, it can be obtained that 
\begin{align*}
\dfrac{d}{dx} \EE{f(x+U)} = \dfrac{1}{\sigma^2}\EE{f(x+U)U} \,,
\end{align*}
where $\hat{f}(\cdot)=\EE{f(\cdot+U)}$ is a smoothed version of $f(\cdot)$. This gradient estimation approach is commonly known as the smoothing technique.

\section{$\mu$ is uniform over some nice set}
\todoc[inline]{Use Gauss-Ostrogradskii to write the derivative.}
Assume $W\subset \cX$ is a convex body with the boundary $\partial W$, $\mu$ is uniform over $W$. Then the derivative can be written as for $y\in \partial W$,
\begin{align*}
\mu'(dy) = \dfrac{\vert \partial W \vert}{\vert W \vert}n_W(y) \nu(dy) \,,
\end{align*}
where $\nu$ is uniform over $\partial W$, $n_W(y)$ denotes the normal vector of $W$ at $y$, and $\vert \cdot\vert$ denotes the volume.

\end{document}
